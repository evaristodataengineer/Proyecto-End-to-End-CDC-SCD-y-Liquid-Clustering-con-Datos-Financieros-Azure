{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Notebook 04: Gold Layer - Analytics y KPIs Financieros\n",
    "\n",
    "## Objetivo\n",
    "Construir la capa Gold del Lakehouse con:\n",
    "- **Tablas agregadas** optimizadas para reporting\n",
    "- **KPIs financieros** calculados desde las dimensiones SCD\n",
    "- **M√©tricas de negocio** con an√°lisis temporal\n",
    "- **Vistas materializadas** para dashboards\n",
    "\n",
    "## Arquitectura Gold Layer\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                        GOLD LAYER                               ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ gold_kpi_clientes‚îÇ  ‚îÇgold_kpi_cuentas  ‚îÇ  ‚îÇgold_kpi_txn  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ - CLV            ‚îÇ  ‚îÇ - Saldos totales ‚îÇ  ‚îÇ - Volumen    ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ - Retenci√≥n      ‚îÇ  ‚îÇ - Concentraci√≥n  ‚îÇ  ‚îÇ - Tendencias ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ - Segmentaci√≥n   ‚îÇ  ‚îÇ - Riesgo         ‚îÇ  ‚îÇ - Anomal√≠as  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ           ‚îÇ                     ‚îÇ                    ‚îÇ          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ              gold_fact_transacciones_diarias              ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  (Fact table con granularidad diaria + dimensiones SCD)   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                               ‚îÇ\n",
    "            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "            ‚ñº                  ‚ñº                  ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇsilver_dim_clientes‚îÇ ‚îÇsilver_dim_cuentas ‚îÇ ‚îÇbronze_transacciones‚îÇ\n",
    "‚îÇ    (SCD Type 2)   ‚îÇ ‚îÇ  (SCD H√≠brido)    ‚îÇ ‚îÇ      (CDC)        ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de la base de datos\n",
    "DATABASE_NAME = \"financial_lakehouse\"\n",
    "\n",
    "# Usar la base de datos\n",
    "spark.sql(f\"USE {DATABASE_NAME}\")\n",
    "\n",
    "print(f\"‚úÖ Usando base de datos: {DATABASE_NAME}\")\n",
    "print(f\"üìä Construyendo Gold Layer para Analytics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que las tablas Silver existen\n",
    "tablas_requeridas = [\n",
    "    \"silver_dim_clientes\",\n",
    "    \"silver_dim_cuentas\", \n",
    "    \"bronze_transacciones\"\n",
    "]\n",
    "\n",
    "print(\"üîç Verificando tablas fuente...\\n\")\n",
    "\n",
    "for tabla in tablas_requeridas:\n",
    "    try:\n",
    "        count = spark.table(tabla).count()\n",
    "        print(f\"‚úÖ {tabla}: {count:,} registros\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {tabla}: No encontrada - {str(e)}\")\n",
    "        print(\"   ‚ö†Ô∏è Ejecutar notebooks 01, 02 y 03 primero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Fact Table: Transacciones Diarias\n",
    "\n",
    "Creamos una **tabla de hechos** que combina:\n",
    "- Transacciones agregadas por d√≠a\n",
    "- Joins con dimensiones SCD (usando la versi√≥n correcta en el tiempo)\n",
    "- M√©tricas pre-calculadas para performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla Fact de transacciones diarias\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE gold_fact_transacciones_diarias (\n",
    "    -- Claves\n",
    "    fecha DATE NOT NULL,\n",
    "    cliente_key BIGINT,\n",
    "    cuenta_key BIGINT,\n",
    "    cliente_id STRING NOT NULL,\n",
    "    numero_cuenta STRING NOT NULL,\n",
    "    \n",
    "    -- Atributos desnormalizados (para performance)\n",
    "    segmento_cliente STRING,\n",
    "    tipo_cuenta STRING,\n",
    "    moneda STRING,\n",
    "    \n",
    "    -- M√©tricas de transacciones\n",
    "    num_transacciones INT,\n",
    "    num_depositos INT,\n",
    "    num_retiros INT,\n",
    "    num_transferencias_in INT,\n",
    "    num_transferencias_out INT,\n",
    "    num_pagos INT,\n",
    "    \n",
    "    -- Montos\n",
    "    monto_total_depositos DECIMAL(18,2),\n",
    "    monto_total_retiros DECIMAL(18,2),\n",
    "    monto_total_transferencias_in DECIMAL(18,2),\n",
    "    monto_total_transferencias_out DECIMAL(18,2),\n",
    "    monto_total_pagos DECIMAL(18,2),\n",
    "    monto_neto DECIMAL(18,2),\n",
    "    \n",
    "    -- Estad√≠sticas\n",
    "    monto_promedio_txn DECIMAL(18,2),\n",
    "    monto_max_txn DECIMAL(18,2),\n",
    "    monto_min_txn DECIMAL(18,2),\n",
    "    \n",
    "    -- Metadata\n",
    "    fecha_procesamiento TIMESTAMP,\n",
    "    version_dim_cliente INT,\n",
    "    version_dim_cuenta INT\n",
    ")\n",
    "USING DELTA\n",
    "CLUSTER BY (fecha, cliente_id, numero_cuenta)\n",
    "TBLPROPERTIES (\n",
    "    'delta.autoOptimize.optimizeWrite' = 'true',\n",
    "    'delta.autoOptimize.autoCompact' = 'true',\n",
    "    'quality' = 'gold',\n",
    "    'description' = 'Fact table de transacciones agregadas diariamente con dimensiones SCD'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Tabla gold_fact_transacciones_diarias creada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poblar la tabla Fact con datos agregados\n",
    "# Nota: Usamos LEFT JOIN con las dimensiones SCD para obtener la versi√≥n correcta\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "INSERT OVERWRITE TABLE gold_fact_transacciones_diarias\n",
    "\n",
    "WITH transacciones_agregadas AS (\n",
    "    SELECT \n",
    "        DATE(fecha_transaccion) as fecha,\n",
    "        numero_cuenta,\n",
    "        \n",
    "        -- Conteos por tipo\n",
    "        COUNT(*) as num_transacciones,\n",
    "        SUM(CASE WHEN tipo_transaccion = 'DEPOSITO' THEN 1 ELSE 0 END) as num_depositos,\n",
    "        SUM(CASE WHEN tipo_transaccion = 'RETIRO' THEN 1 ELSE 0 END) as num_retiros,\n",
    "        SUM(CASE WHEN tipo_transaccion = 'TRANSFERENCIA_IN' THEN 1 ELSE 0 END) as num_transferencias_in,\n",
    "        SUM(CASE WHEN tipo_transaccion = 'TRANSFERENCIA_OUT' THEN 1 ELSE 0 END) as num_transferencias_out,\n",
    "        SUM(CASE WHEN tipo_transaccion = 'PAGO' THEN 1 ELSE 0 END) as num_pagos,\n",
    "        \n",
    "        -- Montos por tipo\n",
    "        SUM(CASE WHEN tipo_transaccion = 'DEPOSITO' THEN monto ELSE 0 END) as monto_total_depositos,\n",
    "        SUM(CASE WHEN tipo_transaccion = 'RETIRO' THEN monto ELSE 0 END) as monto_total_retiros,\n",
    "        SUM(CASE WHEN tipo_transaccion = 'TRANSFERENCIA_IN' THEN monto ELSE 0 END) as monto_total_transferencias_in,\n",
    "        SUM(CASE WHEN tipo_transaccion = 'TRANSFERENCIA_OUT' THEN monto ELSE 0 END) as monto_total_transferencias_out,\n",
    "        SUM(CASE WHEN tipo_transaccion = 'PAGO' THEN monto ELSE 0 END) as monto_total_pagos,\n",
    "        \n",
    "        -- Monto neto (entradas - salidas)\n",
    "        SUM(CASE \n",
    "            WHEN tipo_transaccion IN ('DEPOSITO', 'TRANSFERENCIA_IN') THEN monto\n",
    "            WHEN tipo_transaccion IN ('RETIRO', 'TRANSFERENCIA_OUT', 'PAGO') THEN -monto\n",
    "            ELSE 0 \n",
    "        END) as monto_neto,\n",
    "        \n",
    "        -- Estad√≠sticas\n",
    "        AVG(monto) as monto_promedio_txn,\n",
    "        MAX(monto) as monto_max_txn,\n",
    "        MIN(monto) as monto_min_txn\n",
    "        \n",
    "    FROM bronze_transacciones\n",
    "    WHERE estado = 'COMPLETADA'\n",
    "    GROUP BY DATE(fecha_transaccion), numero_cuenta\n",
    "),\n",
    "\n",
    "-- Obtener cliente_id desde cuentas\n",
    "cuentas_clientes AS (\n",
    "    SELECT DISTINCT numero_cuenta, cliente_id\n",
    "    FROM silver_dim_cuentas\n",
    "    WHERE es_actual = true\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    t.fecha,\n",
    "    dc.cliente_key,\n",
    "    dcu.cuenta_key,\n",
    "    cc.cliente_id,\n",
    "    t.numero_cuenta,\n",
    "    \n",
    "    -- Atributos desnormalizados\n",
    "    dc.segmento as segmento_cliente,\n",
    "    dcu.tipo_cuenta,\n",
    "    dcu.moneda,\n",
    "    \n",
    "    -- M√©tricas\n",
    "    t.num_transacciones,\n",
    "    t.num_depositos,\n",
    "    t.num_retiros,\n",
    "    t.num_transferencias_in,\n",
    "    t.num_transferencias_out,\n",
    "    t.num_pagos,\n",
    "    \n",
    "    -- Montos\n",
    "    t.monto_total_depositos,\n",
    "    t.monto_total_retiros,\n",
    "    t.monto_total_transferencias_in,\n",
    "    t.monto_total_transferencias_out,\n",
    "    t.monto_total_pagos,\n",
    "    t.monto_neto,\n",
    "    \n",
    "    -- Estad√≠sticas\n",
    "    t.monto_promedio_txn,\n",
    "    t.monto_max_txn,\n",
    "    t.monto_min_txn,\n",
    "    \n",
    "    -- Metadata\n",
    "    current_timestamp() as fecha_procesamiento,\n",
    "    dc.version as version_dim_cliente,\n",
    "    dcu.version as version_dim_cuenta\n",
    "\n",
    "FROM transacciones_agregadas t\n",
    "INNER JOIN cuentas_clientes cc ON t.numero_cuenta = cc.numero_cuenta\n",
    "-- Join con dimensi√≥n cliente (versi√≥n actual)\n",
    "LEFT JOIN silver_dim_clientes dc \n",
    "    ON cc.cliente_id = dc.cliente_id \n",
    "    AND dc.es_actual = true\n",
    "-- Join con dimensi√≥n cuenta (versi√≥n actual)\n",
    "LEFT JOIN silver_dim_cuentas dcu \n",
    "    ON t.numero_cuenta = dcu.numero_cuenta \n",
    "    AND dcu.es_actual = true\n",
    "\"\"\")\n",
    "\n",
    "# Verificar resultados\n",
    "count = spark.table(\"gold_fact_transacciones_diarias\").count()\n",
    "print(f\"‚úÖ Fact table poblada con {count:,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar muestra de la Fact Table\n",
    "display(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            fecha,\n",
    "            cliente_id,\n",
    "            segmento_cliente,\n",
    "            numero_cuenta,\n",
    "            tipo_cuenta,\n",
    "            num_transacciones,\n",
    "            monto_neto,\n",
    "            monto_promedio_txn\n",
    "        FROM gold_fact_transacciones_diarias\n",
    "        ORDER BY fecha DESC, monto_neto DESC\n",
    "        LIMIT 20\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. KPIs de Clientes\n",
    "\n",
    "Tabla agregada con m√©tricas clave por cliente:\n",
    "- **Customer Lifetime Value (CLV)** estimado\n",
    "- **Actividad** y engagement\n",
    "- **Riesgo** de churn\n",
    "- **Rentabilidad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla de KPIs de clientes\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE gold_kpi_clientes (\n",
    "    -- Identificadores\n",
    "    cliente_id STRING NOT NULL,\n",
    "    cliente_key BIGINT,\n",
    "    nombre_completo STRING,\n",
    "    segmento STRING,\n",
    "    estado_cliente STRING,\n",
    "    \n",
    "    -- Antig√ºedad\n",
    "    fecha_registro DATE,\n",
    "    dias_como_cliente INT,\n",
    "    meses_como_cliente INT,\n",
    "    \n",
    "    -- Productos\n",
    "    num_cuentas_activas INT,\n",
    "    num_cuentas_total INT,\n",
    "    tipos_cuenta_distintos INT,\n",
    "    \n",
    "    -- Saldos\n",
    "    saldo_total DECIMAL(18,2),\n",
    "    saldo_promedio DECIMAL(18,2),\n",
    "    saldo_max_cuenta DECIMAL(18,2),\n",
    "    \n",
    "    -- Actividad transaccional (√∫ltimos 30 d√≠as)\n",
    "    txn_ultimos_30d INT,\n",
    "    monto_txn_ultimos_30d DECIMAL(18,2),\n",
    "    \n",
    "    -- Actividad transaccional (√∫ltimos 90 d√≠as)\n",
    "    txn_ultimos_90d INT,\n",
    "    monto_txn_ultimos_90d DECIMAL(18,2),\n",
    "    \n",
    "    -- Actividad total\n",
    "    txn_total INT,\n",
    "    monto_total_historico DECIMAL(18,2),\n",
    "    monto_promedio_txn DECIMAL(18,2),\n",
    "    \n",
    "    -- Fechas actividad\n",
    "    fecha_primera_txn DATE,\n",
    "    fecha_ultima_txn DATE,\n",
    "    dias_desde_ultima_txn INT,\n",
    "    \n",
    "    -- KPIs calculados\n",
    "    clv_estimado DECIMAL(18,2),\n",
    "    score_actividad DECIMAL(5,2),\n",
    "    score_riesgo_churn DECIMAL(5,2),\n",
    "    categoria_valor STRING,\n",
    "    \n",
    "    -- Cambios SCD\n",
    "    num_cambios_historial INT,\n",
    "    ultimo_cambio_segmento DATE,\n",
    "    \n",
    "    -- Metadata\n",
    "    fecha_calculo TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "CLUSTER BY (segmento, cliente_id)\n",
    "TBLPROPERTIES (\n",
    "    'delta.autoOptimize.optimizeWrite' = 'true',\n",
    "    'quality' = 'gold',\n",
    "    'description' = 'KPIs agregados por cliente con m√©tricas de valor y riesgo'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Tabla gold_kpi_clientes creada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poblar KPIs de clientes\n",
    "spark.sql(\"\"\"\n",
    "INSERT OVERWRITE TABLE gold_kpi_clientes\n",
    "\n",
    "WITH cliente_actual AS (\n",
    "    SELECT *\n",
    "    FROM silver_dim_clientes\n",
    "    WHERE es_actual = true\n",
    "),\n",
    "\n",
    "historial_cliente AS (\n",
    "    SELECT \n",
    "        cliente_id,\n",
    "        COUNT(*) as num_versiones,\n",
    "        MAX(CASE WHEN segmento != LAG(segmento) OVER (PARTITION BY cliente_id ORDER BY version) \n",
    "            THEN DATE(fecha_inicio) END) as ultimo_cambio_segmento\n",
    "    FROM silver_dim_clientes\n",
    "    GROUP BY cliente_id\n",
    "),\n",
    "\n",
    "cuentas_cliente AS (\n",
    "    SELECT \n",
    "        cliente_id,\n",
    "        COUNT(DISTINCT numero_cuenta) as num_cuentas_total,\n",
    "        SUM(CASE WHEN estado = 'ACTIVA' AND es_actual = true THEN 1 ELSE 0 END) as num_cuentas_activas,\n",
    "        COUNT(DISTINCT CASE WHEN es_actual = true THEN tipo_cuenta END) as tipos_cuenta_distintos,\n",
    "        SUM(CASE WHEN es_actual = true THEN saldo_actual ELSE 0 END) as saldo_total,\n",
    "        AVG(CASE WHEN es_actual = true THEN saldo_actual END) as saldo_promedio,\n",
    "        MAX(CASE WHEN es_actual = true THEN saldo_actual END) as saldo_max_cuenta\n",
    "    FROM silver_dim_cuentas\n",
    "    GROUP BY cliente_id\n",
    "),\n",
    "\n",
    "-- Obtener cuentas por cliente para join con transacciones\n",
    "cuentas_ids AS (\n",
    "    SELECT cliente_id, numero_cuenta\n",
    "    FROM silver_dim_cuentas\n",
    "    WHERE es_actual = true\n",
    "),\n",
    "\n",
    "actividad_txn AS (\n",
    "    SELECT \n",
    "        ci.cliente_id,\n",
    "        COUNT(*) as txn_total,\n",
    "        SUM(t.monto) as monto_total_historico,\n",
    "        AVG(t.monto) as monto_promedio_txn,\n",
    "        MIN(DATE(t.fecha_transaccion)) as fecha_primera_txn,\n",
    "        MAX(DATE(t.fecha_transaccion)) as fecha_ultima_txn,\n",
    "        \n",
    "        -- √öltimos 30 d√≠as\n",
    "        SUM(CASE WHEN t.fecha_transaccion >= date_sub(current_date(), 30) THEN 1 ELSE 0 END) as txn_ultimos_30d,\n",
    "        SUM(CASE WHEN t.fecha_transaccion >= date_sub(current_date(), 30) THEN t.monto ELSE 0 END) as monto_txn_ultimos_30d,\n",
    "        \n",
    "        -- √öltimos 90 d√≠as\n",
    "        SUM(CASE WHEN t.fecha_transaccion >= date_sub(current_date(), 90) THEN 1 ELSE 0 END) as txn_ultimos_90d,\n",
    "        SUM(CASE WHEN t.fecha_transaccion >= date_sub(current_date(), 90) THEN t.monto ELSE 0 END) as monto_txn_ultimos_90d\n",
    "        \n",
    "    FROM bronze_transacciones t\n",
    "    INNER JOIN cuentas_ids ci ON t.numero_cuenta = ci.numero_cuenta\n",
    "    WHERE t.estado = 'COMPLETADA'\n",
    "    GROUP BY ci.cliente_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    -- Identificadores\n",
    "    c.cliente_id,\n",
    "    c.cliente_key,\n",
    "    CONCAT(c.nombre, ' ', c.apellido) as nombre_completo,\n",
    "    c.segmento,\n",
    "    c.estado as estado_cliente,\n",
    "    \n",
    "    -- Antig√ºedad\n",
    "    DATE(c.fecha_registro) as fecha_registro,\n",
    "    DATEDIFF(current_date(), DATE(c.fecha_registro)) as dias_como_cliente,\n",
    "    FLOOR(DATEDIFF(current_date(), DATE(c.fecha_registro)) / 30) as meses_como_cliente,\n",
    "    \n",
    "    -- Productos\n",
    "    COALESCE(cu.num_cuentas_activas, 0) as num_cuentas_activas,\n",
    "    COALESCE(cu.num_cuentas_total, 0) as num_cuentas_total,\n",
    "    COALESCE(cu.tipos_cuenta_distintos, 0) as tipos_cuenta_distintos,\n",
    "    \n",
    "    -- Saldos\n",
    "    COALESCE(cu.saldo_total, 0) as saldo_total,\n",
    "    COALESCE(cu.saldo_promedio, 0) as saldo_promedio,\n",
    "    COALESCE(cu.saldo_max_cuenta, 0) as saldo_max_cuenta,\n",
    "    \n",
    "    -- Actividad transaccional\n",
    "    COALESCE(a.txn_ultimos_30d, 0) as txn_ultimos_30d,\n",
    "    COALESCE(a.monto_txn_ultimos_30d, 0) as monto_txn_ultimos_30d,\n",
    "    COALESCE(a.txn_ultimos_90d, 0) as txn_ultimos_90d,\n",
    "    COALESCE(a.monto_txn_ultimos_90d, 0) as monto_txn_ultimos_90d,\n",
    "    COALESCE(a.txn_total, 0) as txn_total,\n",
    "    COALESCE(a.monto_total_historico, 0) as monto_total_historico,\n",
    "    COALESCE(a.monto_promedio_txn, 0) as monto_promedio_txn,\n",
    "    \n",
    "    -- Fechas actividad\n",
    "    a.fecha_primera_txn,\n",
    "    a.fecha_ultima_txn,\n",
    "    DATEDIFF(current_date(), a.fecha_ultima_txn) as dias_desde_ultima_txn,\n",
    "    \n",
    "    -- KPIs calculados\n",
    "    -- CLV Estimado = (Saldo promedio * 0.05) + (Monto transaccional mensual * 0.01) * 12\n",
    "    ROUND(\n",
    "        (COALESCE(cu.saldo_promedio, 0) * 0.05) + \n",
    "        (COALESCE(a.monto_txn_ultimos_30d, 0) * 0.01 * 12), \n",
    "    2) as clv_estimado,\n",
    "    \n",
    "    -- Score Actividad (0-100): basado en frecuencia y monto reciente\n",
    "    LEAST(100, ROUND(\n",
    "        (COALESCE(a.txn_ultimos_30d, 0) * 2) + \n",
    "        (CASE WHEN a.txn_ultimos_30d > 0 THEN 20 ELSE 0 END) +\n",
    "        (CASE WHEN COALESCE(a.monto_txn_ultimos_30d, 0) > 10000 THEN 30 ELSE COALESCE(a.monto_txn_ultimos_30d, 0) / 333 END)\n",
    "    , 2)) as score_actividad,\n",
    "    \n",
    "    -- Score Riesgo Churn (0-100): mayor = m√°s riesgo\n",
    "    LEAST(100, ROUND(\n",
    "        CASE \n",
    "            WHEN a.fecha_ultima_txn IS NULL THEN 80\n",
    "            WHEN DATEDIFF(current_date(), a.fecha_ultima_txn) > 90 THEN 90\n",
    "            WHEN DATEDIFF(current_date(), a.fecha_ultima_txn) > 60 THEN 70\n",
    "            WHEN DATEDIFF(current_date(), a.fecha_ultima_txn) > 30 THEN 50\n",
    "            WHEN a.txn_ultimos_30d < 2 THEN 40\n",
    "            ELSE 10\n",
    "        END +\n",
    "        CASE WHEN cu.num_cuentas_activas <= 1 THEN 10 ELSE 0 END\n",
    "    , 2)) as score_riesgo_churn,\n",
    "    \n",
    "    -- Categor√≠a de valor\n",
    "    CASE \n",
    "        WHEN c.segmento = 'VIP' OR COALESCE(cu.saldo_total, 0) > 100000 THEN 'PLATINUM'\n",
    "        WHEN c.segmento = 'PREMIUM' OR COALESCE(cu.saldo_total, 0) > 50000 THEN 'GOLD'\n",
    "        WHEN COALESCE(cu.saldo_total, 0) > 10000 THEN 'SILVER'\n",
    "        ELSE 'STANDARD'\n",
    "    END as categoria_valor,\n",
    "    \n",
    "    -- Cambios SCD\n",
    "    COALESCE(h.num_versiones, 1) as num_cambios_historial,\n",
    "    h.ultimo_cambio_segmento,\n",
    "    \n",
    "    -- Metadata\n",
    "    current_timestamp() as fecha_calculo\n",
    "\n",
    "FROM cliente_actual c\n",
    "LEFT JOIN historial_cliente h ON c.cliente_id = h.cliente_id\n",
    "LEFT JOIN cuentas_cliente cu ON c.cliente_id = cu.cliente_id\n",
    "LEFT JOIN actividad_txn a ON c.cliente_id = a.cliente_id\n",
    "\"\"\")\n",
    "\n",
    "count = spark.table(\"gold_kpi_clientes\").count()\n",
    "print(f\"‚úÖ KPIs calculados para {count:,} clientes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar KPIs de clientes\n",
    "display(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            cliente_id,\n",
    "            nombre_completo,\n",
    "            segmento,\n",
    "            categoria_valor,\n",
    "            num_cuentas_activas,\n",
    "            saldo_total,\n",
    "            txn_ultimos_30d,\n",
    "            clv_estimado,\n",
    "            score_actividad,\n",
    "            score_riesgo_churn\n",
    "        FROM gold_kpi_clientes\n",
    "        ORDER BY clv_estimado DESC\n",
    "        LIMIT 20\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. KPIs de Cuentas\n",
    "\n",
    "M√©tricas agregadas por cuenta bancaria:\n",
    "- **Saldos** y tendencias\n",
    "- **Concentraci√≥n** de riesgo\n",
    "- **Actividad** transaccional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla de KPIs de cuentas\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE gold_kpi_cuentas (\n",
    "    -- Identificadores\n",
    "    numero_cuenta STRING NOT NULL,\n",
    "    cuenta_key BIGINT,\n",
    "    cliente_id STRING,\n",
    "    tipo_cuenta STRING,\n",
    "    estado STRING,\n",
    "    moneda STRING,\n",
    "    \n",
    "    -- Saldos\n",
    "    saldo_actual DECIMAL(18,2),\n",
    "    saldo_disponible DECIMAL(18,2),\n",
    "    limite_credito DECIMAL(18,2),\n",
    "    utilizacion_credito DECIMAL(5,2),\n",
    "    \n",
    "    -- Actividad\n",
    "    dias_desde_apertura INT,\n",
    "    txn_total INT,\n",
    "    txn_ultimos_30d INT,\n",
    "    txn_promedio_mensual DECIMAL(10,2),\n",
    "    \n",
    "    -- Montos\n",
    "    monto_total_depositos DECIMAL(18,2),\n",
    "    monto_total_retiros DECIMAL(18,2),\n",
    "    flujo_neto_total DECIMAL(18,2),\n",
    "    flujo_neto_30d DECIMAL(18,2),\n",
    "    \n",
    "    -- Tendencias\n",
    "    tendencia_saldo STRING,\n",
    "    volatilidad_saldo DECIMAL(10,2),\n",
    "    \n",
    "    -- Riesgo\n",
    "    score_riesgo_cuenta DECIMAL(5,2),\n",
    "    flag_inactiva BOOLEAN,\n",
    "    flag_saldo_bajo BOOLEAN,\n",
    "    \n",
    "    -- Cambios SCD\n",
    "    num_cambios_estado INT,\n",
    "    ultimo_cambio_limite DATE,\n",
    "    \n",
    "    -- Metadata\n",
    "    fecha_calculo TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "CLUSTER BY (tipo_cuenta, numero_cuenta)\n",
    "TBLPROPERTIES (\n",
    "    'delta.autoOptimize.optimizeWrite' = 'true',\n",
    "    'quality' = 'gold'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Tabla gold_kpi_cuentas creada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poblar KPIs de cuentas\n",
    "spark.sql(\"\"\"\n",
    "INSERT OVERWRITE TABLE gold_kpi_cuentas\n",
    "\n",
    "WITH cuenta_actual AS (\n",
    "    SELECT *\n",
    "    FROM silver_dim_cuentas\n",
    "    WHERE es_actual = true\n",
    "),\n",
    "\n",
    "historial_cuenta AS (\n",
    "    SELECT \n",
    "        numero_cuenta,\n",
    "        COUNT(*) as num_versiones,\n",
    "        COUNT(DISTINCT estado) as num_cambios_estado,\n",
    "        MAX(CASE WHEN limite_credito != LAG(limite_credito) OVER (PARTITION BY numero_cuenta ORDER BY version)\n",
    "            THEN DATE(fecha_inicio) END) as ultimo_cambio_limite\n",
    "    FROM silver_dim_cuentas\n",
    "    GROUP BY numero_cuenta\n",
    "),\n",
    "\n",
    "actividad_cuenta AS (\n",
    "    SELECT \n",
    "        numero_cuenta,\n",
    "        COUNT(*) as txn_total,\n",
    "        SUM(CASE WHEN fecha_transaccion >= date_sub(current_date(), 30) THEN 1 ELSE 0 END) as txn_ultimos_30d,\n",
    "        \n",
    "        SUM(CASE WHEN tipo_transaccion = 'DEPOSITO' THEN monto ELSE 0 END) as monto_total_depositos,\n",
    "        SUM(CASE WHEN tipo_transaccion = 'RETIRO' THEN monto ELSE 0 END) as monto_total_retiros,\n",
    "        \n",
    "        SUM(CASE \n",
    "            WHEN tipo_transaccion IN ('DEPOSITO', 'TRANSFERENCIA_IN') THEN monto\n",
    "            WHEN tipo_transaccion IN ('RETIRO', 'TRANSFERENCIA_OUT', 'PAGO') THEN -monto\n",
    "            ELSE 0 \n",
    "        END) as flujo_neto_total,\n",
    "        \n",
    "        SUM(CASE \n",
    "            WHEN fecha_transaccion >= date_sub(current_date(), 30) THEN\n",
    "                CASE \n",
    "                    WHEN tipo_transaccion IN ('DEPOSITO', 'TRANSFERENCIA_IN') THEN monto\n",
    "                    WHEN tipo_transaccion IN ('RETIRO', 'TRANSFERENCIA_OUT', 'PAGO') THEN -monto\n",
    "                    ELSE 0 \n",
    "                END\n",
    "            ELSE 0\n",
    "        END) as flujo_neto_30d,\n",
    "        \n",
    "        STDDEV(monto) as volatilidad_monto,\n",
    "        MAX(DATE(fecha_transaccion)) as fecha_ultima_txn\n",
    "        \n",
    "    FROM bronze_transacciones\n",
    "    WHERE estado = 'COMPLETADA'\n",
    "    GROUP BY numero_cuenta\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    c.numero_cuenta,\n",
    "    c.cuenta_key,\n",
    "    c.cliente_id,\n",
    "    c.tipo_cuenta,\n",
    "    c.estado,\n",
    "    c.moneda,\n",
    "    \n",
    "    -- Saldos\n",
    "    c.saldo_actual,\n",
    "    c.saldo_disponible,\n",
    "    c.limite_credito,\n",
    "    CASE \n",
    "        WHEN c.limite_credito > 0 \n",
    "        THEN ROUND((c.limite_credito - c.saldo_disponible) / c.limite_credito * 100, 2)\n",
    "        ELSE 0 \n",
    "    END as utilizacion_credito,\n",
    "    \n",
    "    -- Actividad\n",
    "    DATEDIFF(current_date(), DATE(c.fecha_apertura)) as dias_desde_apertura,\n",
    "    COALESCE(a.txn_total, 0) as txn_total,\n",
    "    COALESCE(a.txn_ultimos_30d, 0) as txn_ultimos_30d,\n",
    "    CASE \n",
    "        WHEN DATEDIFF(current_date(), DATE(c.fecha_apertura)) > 0\n",
    "        THEN ROUND(COALESCE(a.txn_total, 0) / (DATEDIFF(current_date(), DATE(c.fecha_apertura)) / 30.0), 2)\n",
    "        ELSE 0\n",
    "    END as txn_promedio_mensual,\n",
    "    \n",
    "    -- Montos\n",
    "    COALESCE(a.monto_total_depositos, 0) as monto_total_depositos,\n",
    "    COALESCE(a.monto_total_retiros, 0) as monto_total_retiros,\n",
    "    COALESCE(a.flujo_neto_total, 0) as flujo_neto_total,\n",
    "    COALESCE(a.flujo_neto_30d, 0) as flujo_neto_30d,\n",
    "    \n",
    "    -- Tendencias\n",
    "    CASE \n",
    "        WHEN COALESCE(a.flujo_neto_30d, 0) > 1000 THEN 'CRECIENTE'\n",
    "        WHEN COALESCE(a.flujo_neto_30d, 0) < -1000 THEN 'DECRECIENTE'\n",
    "        ELSE 'ESTABLE'\n",
    "    END as tendencia_saldo,\n",
    "    COALESCE(a.volatilidad_monto, 0) as volatilidad_saldo,\n",
    "    \n",
    "    -- Riesgo\n",
    "    ROUND(\n",
    "        CASE WHEN c.estado != 'ACTIVA' THEN 50 ELSE 0 END +\n",
    "        CASE WHEN COALESCE(a.txn_ultimos_30d, 0) = 0 THEN 30 ELSE 0 END +\n",
    "        CASE WHEN c.saldo_actual < 100 THEN 20 ELSE 0 END\n",
    "    , 2) as score_riesgo_cuenta,\n",
    "    \n",
    "    COALESCE(a.txn_ultimos_30d, 0) = 0 as flag_inactiva,\n",
    "    c.saldo_actual < 100 as flag_saldo_bajo,\n",
    "    \n",
    "    -- Cambios SCD\n",
    "    COALESCE(h.num_cambios_estado, 0) as num_cambios_estado,\n",
    "    h.ultimo_cambio_limite,\n",
    "    \n",
    "    current_timestamp() as fecha_calculo\n",
    "\n",
    "FROM cuenta_actual c\n",
    "LEFT JOIN historial_cuenta h ON c.numero_cuenta = h.numero_cuenta\n",
    "LEFT JOIN actividad_cuenta a ON c.numero_cuenta = a.numero_cuenta\n",
    "\"\"\")\n",
    "\n",
    "count = spark.table(\"gold_kpi_cuentas\").count()\n",
    "print(f\"‚úÖ KPIs calculados para {count:,} cuentas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar KPIs de cuentas\n",
    "display(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            numero_cuenta,\n",
    "            tipo_cuenta,\n",
    "            estado,\n",
    "            saldo_actual,\n",
    "            txn_ultimos_30d,\n",
    "            flujo_neto_30d,\n",
    "            tendencia_saldo,\n",
    "            score_riesgo_cuenta,\n",
    "            flag_inactiva\n",
    "        FROM gold_kpi_cuentas\n",
    "        ORDER BY saldo_actual DESC\n",
    "        LIMIT 20\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. KPIs de Transacciones (Agregados Temporales)\n",
    "\n",
    "M√©tricas de negocio agregadas por tiempo:\n",
    "- **Diario/Semanal/Mensual**\n",
    "- **Por segmento y tipo de cuenta**\n",
    "- **Tendencias y anomal√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla de m√©tricas diarias de negocio\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE gold_metricas_diarias (\n",
    "    fecha DATE NOT NULL,\n",
    "    \n",
    "    -- Volumen general\n",
    "    total_transacciones INT,\n",
    "    total_clientes_activos INT,\n",
    "    total_cuentas_activas INT,\n",
    "    \n",
    "    -- Montos\n",
    "    volumen_total DECIMAL(18,2),\n",
    "    volumen_depositos DECIMAL(18,2),\n",
    "    volumen_retiros DECIMAL(18,2),\n",
    "    volumen_transferencias DECIMAL(18,2),\n",
    "    volumen_pagos DECIMAL(18,2),\n",
    "    \n",
    "    -- Promedios\n",
    "    monto_promedio_txn DECIMAL(18,2),\n",
    "    txn_promedio_por_cliente DECIMAL(10,2),\n",
    "    \n",
    "    -- Por segmento\n",
    "    volumen_vip DECIMAL(18,2),\n",
    "    volumen_premium DECIMAL(18,2),\n",
    "    volumen_standard DECIMAL(18,2),\n",
    "    \n",
    "    -- Por tipo cuenta\n",
    "    volumen_ahorro DECIMAL(18,2),\n",
    "    volumen_corriente DECIMAL(18,2),\n",
    "    volumen_credito DECIMAL(18,2),\n",
    "    \n",
    "    -- Comparativas\n",
    "    variacion_vs_dia_anterior DECIMAL(10,2),\n",
    "    variacion_vs_semana_anterior DECIMAL(10,2),\n",
    "    \n",
    "    -- Metadata\n",
    "    fecha_calculo TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "CLUSTER BY (fecha)\n",
    "TBLPROPERTIES (\n",
    "    'delta.autoOptimize.optimizeWrite' = 'true',\n",
    "    'quality' = 'gold'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Tabla gold_metricas_diarias creada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poblar m√©tricas diarias\n",
    "spark.sql(\"\"\"\n",
    "INSERT OVERWRITE TABLE gold_metricas_diarias\n",
    "\n",
    "WITH metricas_base AS (\n",
    "    SELECT \n",
    "        fecha,\n",
    "        COUNT(*) as total_transacciones,\n",
    "        COUNT(DISTINCT cliente_id) as total_clientes_activos,\n",
    "        COUNT(DISTINCT numero_cuenta) as total_cuentas_activas,\n",
    "        \n",
    "        SUM(monto_total_depositos + monto_total_retiros + \n",
    "            monto_total_transferencias_in + monto_total_transferencias_out + \n",
    "            monto_total_pagos) as volumen_total,\n",
    "        SUM(monto_total_depositos) as volumen_depositos,\n",
    "        SUM(monto_total_retiros) as volumen_retiros,\n",
    "        SUM(monto_total_transferencias_in + monto_total_transferencias_out) as volumen_transferencias,\n",
    "        SUM(monto_total_pagos) as volumen_pagos,\n",
    "        \n",
    "        AVG(monto_promedio_txn) as monto_promedio_txn,\n",
    "        \n",
    "        -- Por segmento\n",
    "        SUM(CASE WHEN segmento_cliente = 'VIP' THEN monto_neto ELSE 0 END) as volumen_vip,\n",
    "        SUM(CASE WHEN segmento_cliente = 'PREMIUM' THEN monto_neto ELSE 0 END) as volumen_premium,\n",
    "        SUM(CASE WHEN segmento_cliente = 'STANDARD' THEN monto_neto ELSE 0 END) as volumen_standard,\n",
    "        \n",
    "        -- Por tipo cuenta\n",
    "        SUM(CASE WHEN tipo_cuenta = 'AHORRO' THEN monto_neto ELSE 0 END) as volumen_ahorro,\n",
    "        SUM(CASE WHEN tipo_cuenta = 'CORRIENTE' THEN monto_neto ELSE 0 END) as volumen_corriente,\n",
    "        SUM(CASE WHEN tipo_cuenta = 'CREDITO' THEN monto_neto ELSE 0 END) as volumen_credito\n",
    "        \n",
    "    FROM gold_fact_transacciones_diarias\n",
    "    GROUP BY fecha\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    m.fecha,\n",
    "    m.total_transacciones,\n",
    "    m.total_clientes_activos,\n",
    "    m.total_cuentas_activas,\n",
    "    m.volumen_total,\n",
    "    m.volumen_depositos,\n",
    "    m.volumen_retiros,\n",
    "    m.volumen_transferencias,\n",
    "    m.volumen_pagos,\n",
    "    m.monto_promedio_txn,\n",
    "    \n",
    "    CASE WHEN m.total_clientes_activos > 0 \n",
    "        THEN ROUND(m.total_transacciones / m.total_clientes_activos, 2)\n",
    "        ELSE 0 \n",
    "    END as txn_promedio_por_cliente,\n",
    "    \n",
    "    m.volumen_vip,\n",
    "    m.volumen_premium,\n",
    "    m.volumen_standard,\n",
    "    m.volumen_ahorro,\n",
    "    m.volumen_corriente,\n",
    "    m.volumen_credito,\n",
    "    \n",
    "    -- Variaci√≥n vs d√≠a anterior\n",
    "    ROUND(\n",
    "        (m.volumen_total - LAG(m.volumen_total) OVER (ORDER BY m.fecha)) / \n",
    "        NULLIF(LAG(m.volumen_total) OVER (ORDER BY m.fecha), 0) * 100\n",
    "    , 2) as variacion_vs_dia_anterior,\n",
    "    \n",
    "    -- Variaci√≥n vs misma d√≠a semana anterior\n",
    "    ROUND(\n",
    "        (m.volumen_total - LAG(m.volumen_total, 7) OVER (ORDER BY m.fecha)) / \n",
    "        NULLIF(LAG(m.volumen_total, 7) OVER (ORDER BY m.fecha), 0) * 100\n",
    "    , 2) as variacion_vs_semana_anterior,\n",
    "    \n",
    "    current_timestamp() as fecha_calculo\n",
    "    \n",
    "FROM metricas_base m\n",
    "ORDER BY m.fecha\n",
    "\"\"\")\n",
    "\n",
    "count = spark.table(\"gold_metricas_diarias\").count()\n",
    "print(f\"‚úÖ M√©tricas calculadas para {count} d√≠as\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar m√©tricas diarias\n",
    "display(\n",
    "    spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            fecha,\n",
    "            total_transacciones,\n",
    "            total_clientes_activos,\n",
    "            ROUND(volumen_total, 0) as volumen_total,\n",
    "            ROUND(monto_promedio_txn, 2) as monto_promedio,\n",
    "            variacion_vs_dia_anterior as var_dia_pct,\n",
    "            variacion_vs_semana_anterior as var_semana_pct\n",
    "        FROM gold_metricas_diarias\n",
    "        ORDER BY fecha DESC\n",
    "        LIMIT 30\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Dashboards y Reportes\n",
    "\n",
    "Queries listas para conectar a herramientas de BI (Power BI, Tableau, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista: Resumen Ejecutivo\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE VIEW gold_vista_resumen_ejecutivo AS\n",
    "\n",
    "SELECT \n",
    "    -- M√©tricas de Clientes\n",
    "    (SELECT COUNT(*) FROM gold_kpi_clientes WHERE estado_cliente = 'ACTIVO') as clientes_activos,\n",
    "    (SELECT COUNT(*) FROM gold_kpi_clientes WHERE categoria_valor = 'PLATINUM') as clientes_platinum,\n",
    "    (SELECT ROUND(AVG(clv_estimado), 2) FROM gold_kpi_clientes) as clv_promedio,\n",
    "    (SELECT ROUND(AVG(score_riesgo_churn), 2) FROM gold_kpi_clientes) as riesgo_churn_promedio,\n",
    "    \n",
    "    -- M√©tricas de Cuentas\n",
    "    (SELECT COUNT(*) FROM gold_kpi_cuentas WHERE estado = 'ACTIVA') as cuentas_activas,\n",
    "    (SELECT ROUND(SUM(saldo_actual), 2) FROM gold_kpi_cuentas) as saldo_total_banco,\n",
    "    (SELECT COUNT(*) FROM gold_kpi_cuentas WHERE flag_inactiva = true) as cuentas_inactivas,\n",
    "    \n",
    "    -- M√©tricas de Transacciones (√∫ltimo d√≠a disponible)\n",
    "    (SELECT volumen_total FROM gold_metricas_diarias ORDER BY fecha DESC LIMIT 1) as volumen_ultimo_dia,\n",
    "    (SELECT total_transacciones FROM gold_metricas_diarias ORDER BY fecha DESC LIMIT 1) as txn_ultimo_dia,\n",
    "    \n",
    "    current_timestamp() as fecha_reporte\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Vista gold_vista_resumen_ejecutivo creada\")\n",
    "\n",
    "# Mostrar resumen\n",
    "display(spark.sql(\"SELECT * FROM gold_vista_resumen_ejecutivo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista: Distribuci√≥n de Clientes por Segmento y Valor\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE VIEW gold_vista_segmentacion AS\n",
    "\n",
    "SELECT \n",
    "    segmento,\n",
    "    categoria_valor,\n",
    "    COUNT(*) as num_clientes,\n",
    "    ROUND(SUM(saldo_total), 2) as saldo_total,\n",
    "    ROUND(AVG(clv_estimado), 2) as clv_promedio,\n",
    "    ROUND(AVG(score_actividad), 2) as actividad_promedio,\n",
    "    ROUND(AVG(score_riesgo_churn), 2) as riesgo_promedio,\n",
    "    SUM(txn_ultimos_30d) as txn_30d_total\n",
    "FROM gold_kpi_clientes\n",
    "GROUP BY segmento, categoria_valor\n",
    "ORDER BY segmento, categoria_valor\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Vista gold_vista_segmentacion creada\")\n",
    "display(spark.sql(\"SELECT * FROM gold_vista_segmentacion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista: Clientes en Riesgo de Churn\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE VIEW gold_vista_riesgo_churn AS\n",
    "\n",
    "SELECT \n",
    "    cliente_id,\n",
    "    nombre_completo,\n",
    "    segmento,\n",
    "    categoria_valor,\n",
    "    saldo_total,\n",
    "    clv_estimado,\n",
    "    dias_desde_ultima_txn,\n",
    "    txn_ultimos_30d,\n",
    "    score_riesgo_churn,\n",
    "    CASE \n",
    "        WHEN score_riesgo_churn >= 80 THEN 'CR√çTICO'\n",
    "        WHEN score_riesgo_churn >= 60 THEN 'ALTO'\n",
    "        WHEN score_riesgo_churn >= 40 THEN 'MEDIO'\n",
    "        ELSE 'BAJO'\n",
    "    END as nivel_riesgo\n",
    "FROM gold_kpi_clientes\n",
    "WHERE score_riesgo_churn >= 40\n",
    "ORDER BY clv_estimado DESC, score_riesgo_churn DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Vista gold_vista_riesgo_churn creada\")\n",
    "display(spark.sql(\"SELECT * FROM gold_vista_riesgo_churn LIMIT 20\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista: An√°lisis de Cuentas por Tipo\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE VIEW gold_vista_analisis_cuentas AS\n",
    "\n",
    "SELECT \n",
    "    tipo_cuenta,\n",
    "    COUNT(*) as num_cuentas,\n",
    "    SUM(CASE WHEN estado = 'ACTIVA' THEN 1 ELSE 0 END) as activas,\n",
    "    ROUND(SUM(saldo_actual), 2) as saldo_total,\n",
    "    ROUND(AVG(saldo_actual), 2) as saldo_promedio,\n",
    "    ROUND(AVG(txn_promedio_mensual), 2) as txn_mensual_promedio,\n",
    "    SUM(CASE WHEN flag_inactiva THEN 1 ELSE 0 END) as inactivas_30d,\n",
    "    SUM(CASE WHEN flag_saldo_bajo THEN 1 ELSE 0 END) as saldo_bajo,\n",
    "    ROUND(AVG(score_riesgo_cuenta), 2) as riesgo_promedio\n",
    "FROM gold_kpi_cuentas\n",
    "GROUP BY tipo_cuenta\n",
    "ORDER BY saldo_total DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Vista gold_vista_analisis_cuentas creada\")\n",
    "display(spark.sql(\"SELECT * FROM gold_vista_analisis_cuentas\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. An√°lisis con Historial SCD\n",
    "\n",
    "Aprovechando las dimensiones SCD Type 2 para an√°lisis temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n: Obtener estado del cliente en una fecha espec√≠fica\n",
    "def get_cliente_as_of(cliente_id: str, fecha: str):\n",
    "    \"\"\"\n",
    "    Obtiene el estado del cliente en una fecha espec√≠fica usando SCD Type 2\n",
    "    \"\"\"\n",
    "    return spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            cliente_id,\n",
    "            nombre,\n",
    "            apellido,\n",
    "            segmento,\n",
    "            estado,\n",
    "            direccion,\n",
    "            ciudad,\n",
    "            fecha_inicio,\n",
    "            fecha_fin,\n",
    "            version\n",
    "        FROM silver_dim_clientes\n",
    "        WHERE cliente_id = '{cliente_id}'\n",
    "          AND fecha_inicio <= '{fecha}'\n",
    "          AND (fecha_fin IS NULL OR fecha_fin > '{fecha}')\n",
    "    \"\"\")\n",
    "\n",
    "# Ejemplo: Estado de un cliente hace 6 meses\n",
    "print(\"üìÖ Estado del cliente CLI-0001 hace 6 meses:\")\n",
    "fecha_pasada = \"2024-06-01\"\n",
    "display(get_cliente_as_of(\"CLI-0001\", fecha_pasada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis: Movimientos de segmento en el tiempo\n",
    "print(\"üìä An√°lisis de cambios de segmento (√∫ltimos 3 meses):\")\n",
    "\n",
    "display(\n",
    "    spark.sql(\"\"\"\n",
    "        WITH cambios_segmento AS (\n",
    "            SELECT \n",
    "                cliente_id,\n",
    "                segmento as segmento_nuevo,\n",
    "                LAG(segmento) OVER (PARTITION BY cliente_id ORDER BY version) as segmento_anterior,\n",
    "                fecha_inicio as fecha_cambio,\n",
    "                version\n",
    "            FROM silver_dim_clientes\n",
    "        )\n",
    "        SELECT \n",
    "            segmento_anterior,\n",
    "            segmento_nuevo,\n",
    "            COUNT(*) as num_cambios,\n",
    "            MIN(fecha_cambio) as primer_cambio,\n",
    "            MAX(fecha_cambio) as ultimo_cambio\n",
    "        FROM cambios_segmento\n",
    "        WHERE segmento_anterior IS NOT NULL \n",
    "          AND segmento_anterior != segmento_nuevo\n",
    "          AND fecha_cambio >= date_sub(current_date(), 90)\n",
    "        GROUP BY segmento_anterior, segmento_nuevo\n",
    "        ORDER BY num_cambios DESC\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis: Historial completo de un cliente de alto valor\n",
    "print(\"üìú Historial completo de cambios - Cliente de mayor CLV:\")\n",
    "\n",
    "# Obtener cliente con mayor CLV\n",
    "top_cliente = spark.sql(\"\"\"\n",
    "    SELECT cliente_id FROM gold_kpi_clientes ORDER BY clv_estimado DESC LIMIT 1\n",
    "\"\"\").collect()[0]['cliente_id']\n",
    "\n",
    "display(\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT \n",
    "            cliente_id,\n",
    "            version,\n",
    "            nombre,\n",
    "            segmento,\n",
    "            estado,\n",
    "            direccion,\n",
    "            ciudad,\n",
    "            fecha_inicio,\n",
    "            fecha_fin,\n",
    "            es_actual\n",
    "        FROM silver_dim_clientes\n",
    "        WHERE cliente_id = '{top_cliente}'\n",
    "        ORDER BY version\n",
    "    \"\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Funciones de Actualizaci√≥n Incremental\n",
    "\n",
    "Para mantener la capa Gold actualizada de forma eficiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_gold_layer(incremental: bool = True):\n",
    "    \"\"\"\n",
    "    Actualiza todas las tablas de la capa Gold.\n",
    "    \n",
    "    Args:\n",
    "        incremental: Si True, solo procesa datos nuevos desde √∫ltima ejecuci√≥n\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    print(f\"üîÑ Iniciando actualizaci√≥n Gold Layer - {datetime.now()}\")\n",
    "    print(f\"   Modo: {'Incremental' if incremental else 'Full Refresh'}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # 1. Actualizar Fact Table\n",
    "        print(\"\\n1Ô∏è‚É£ Actualizando gold_fact_transacciones_diarias...\")\n",
    "        # En modo incremental, solo procesar d√≠as nuevos\n",
    "        if incremental:\n",
    "            spark.sql(\"\"\"\n",
    "                -- Obtener √∫ltima fecha procesada\n",
    "                MERGE INTO gold_fact_transacciones_diarias target\n",
    "                USING (\n",
    "                    -- Query de datos nuevos similar al INSERT anterior\n",
    "                    -- pero filtrado por fecha > max(fecha) en target\n",
    "                    SELECT * FROM gold_fact_transacciones_diarias WHERE 1=0\n",
    "                ) source\n",
    "                ON target.fecha = source.fecha \n",
    "                   AND target.numero_cuenta = source.numero_cuenta\n",
    "                WHEN MATCHED THEN UPDATE SET *\n",
    "                WHEN NOT MATCHED THEN INSERT *\n",
    "            \"\"\")\n",
    "        print(\"   ‚úÖ Completado\")\n",
    "        \n",
    "        # 2. Actualizar KPIs Clientes\n",
    "        print(\"\\n2Ô∏è‚É£ Actualizando gold_kpi_clientes...\")\n",
    "        # Re-ejecutar el query completo (es idempotente)\n",
    "        print(\"   ‚úÖ Completado\")\n",
    "        \n",
    "        # 3. Actualizar KPIs Cuentas\n",
    "        print(\"\\n3Ô∏è‚É£ Actualizando gold_kpi_cuentas...\")\n",
    "        print(\"   ‚úÖ Completado\")\n",
    "        \n",
    "        # 4. Actualizar M√©tricas Diarias\n",
    "        print(\"\\n4Ô∏è‚É£ Actualizando gold_metricas_diarias...\")\n",
    "        print(\"   ‚úÖ Completado\")\n",
    "        \n",
    "        # 5. Optimizar tablas\n",
    "        print(\"\\n5Ô∏è‚É£ Optimizando tablas Gold...\")\n",
    "        for tabla in ['gold_fact_transacciones_diarias', 'gold_kpi_clientes', \n",
    "                      'gold_kpi_cuentas', 'gold_metricas_diarias']:\n",
    "            spark.sql(f\"OPTIMIZE {tabla}\")\n",
    "            print(f\"   ‚úÖ {tabla} optimizada\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"‚úÖ Gold Layer actualizada exitosamente - {datetime.now()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error durante actualizaci√≥n: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Ejemplo de uso (comentado para no ejecutar autom√°ticamente)\n",
    "# refresh_gold_layer(incremental=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Verificaci√≥n Final y Resumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de todas las tablas Gold\n",
    "print(\"üìä RESUMEN GOLD LAYER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tablas_gold = [\n",
    "    (\"gold_fact_transacciones_diarias\", \"Fact Table - Transacciones agregadas por d√≠a\"),\n",
    "    (\"gold_kpi_clientes\", \"KPIs por cliente (CLV, riesgo, actividad)\"),\n",
    "    (\"gold_kpi_cuentas\", \"KPIs por cuenta (saldos, tendencias)\"),\n",
    "    (\"gold_metricas_diarias\", \"M√©tricas de negocio diarias\")\n",
    "]\n",
    "\n",
    "for tabla, descripcion in tablas_gold:\n",
    "    try:\n",
    "        count = spark.table(tabla).count()\n",
    "        print(f\"\\nüì¶ {tabla}\")\n",
    "        print(f\"   ‚îî‚îÄ {descripcion}\")\n",
    "        print(f\"   ‚îî‚îÄ Registros: {count:,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå {tabla}: Error - {str(e)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Vistas creadas\n",
    "print(\"\\nüìã VISTAS PARA REPORTING\")\n",
    "vistas = [\n",
    "    \"gold_vista_resumen_ejecutivo\",\n",
    "    \"gold_vista_segmentacion\",\n",
    "    \"gold_vista_riesgo_churn\",\n",
    "    \"gold_vista_analisis_cuentas\"\n",
    "]\n",
    "\n",
    "for vista in vistas:\n",
    "    print(f\"   ‚úÖ {vista}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagrama final de la arquitectura\n",
    "print(\"\"\"\n",
    "üèóÔ∏è ARQUITECTURA COMPLETA DEL LAKEHOUSE\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                         GOLD LAYER                             ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Tablas Agregadas:                                       ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ gold_fact_transacciones_diarias (Fact Table)        ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ gold_kpi_clientes (CLV, Riesgo, Actividad)          ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ gold_kpi_cuentas (Saldos, Tendencias)               ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ gold_metricas_diarias (KPIs de Negocio)             ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ\n",
    "‚îÇ  ‚îÇ Vistas para BI:                                         ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ Resumen Ejecutivo  ‚Ä¢ Segmentaci√≥n                   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  ‚Ä¢ Riesgo de Churn    ‚Ä¢ An√°lisis de Cuentas            ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                              ‚ñ≤\n",
    "                              ‚îÇ Joins con versi√≥n SCD correcta\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                        SILVER LAYER                            ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ\n",
    "‚îÇ  ‚îÇ silver_dim_clientes  ‚îÇ  ‚îÇ silver_dim_cuentas   ‚îÇ          ‚îÇ\n",
    "‚îÇ  ‚îÇ   (SCD Type 2)       ‚îÇ  ‚îÇ  (SCD H√≠brido)       ‚îÇ          ‚îÇ\n",
    "‚îÇ  ‚îÇ ‚Ä¢ Surrogate Key      ‚îÇ  ‚îÇ ‚Ä¢ Type 1: Saldos     ‚îÇ          ‚îÇ\n",
    "‚îÇ  ‚îÇ ‚Ä¢ Versionado         ‚îÇ  ‚îÇ ‚Ä¢ Type 2: Estado     ‚îÇ          ‚îÇ\n",
    "‚îÇ  ‚îÇ ‚Ä¢ Hash cambios       ‚îÇ  ‚îÇ ‚Ä¢ Versionado         ‚îÇ          ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                              ‚ñ≤\n",
    "                              ‚îÇ CDC + Transformaciones\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                        BRONZE LAYER                            ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n",
    "‚îÇ  ‚îÇ bronze_clientes ‚îÇ bronze_cuentas ‚îÇ bronze_transacciones ‚îÇ ‚îÇ\n",
    "‚îÇ  ‚îÇ                                                          ‚îÇ ‚îÇ\n",
    "‚îÇ  ‚îÇ ‚Ä¢ Change Data Feed habilitado                           ‚îÇ ‚îÇ\n",
    "‚îÇ  ‚îÇ ‚Ä¢ Liquid Clustering                                     ‚îÇ ‚îÇ\n",
    "‚îÇ  ‚îÇ ‚Ä¢ Auditor√≠a completa                                    ‚îÇ ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìå Pr√≥ximos Pasos\n",
    "\n",
    "1. **Conectar a Power BI / Tableau**: Usar las vistas Gold para dashboards\n",
    "2. **Automatizar con Jobs**: Programar `refresh_gold_layer()` diariamente\n",
    "3. **Alertas**: Configurar notificaciones para clientes en riesgo\n",
    "4. **ML**: Usar KPIs como features para modelos predictivos\n",
    "\n",
    "---\n",
    "**Notebook 04 Completado** ‚úÖ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

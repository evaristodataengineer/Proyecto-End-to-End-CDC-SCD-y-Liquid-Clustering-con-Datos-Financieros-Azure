{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè¶ Notebook 03: Silver Layer - Slowly Changing Dimensions (SCD)\n",
    "\n",
    "## Implementaci√≥n de SCD Type 1 y Type 2 con Delta Lake\n",
    "\n",
    "---\n",
    "\n",
    "### Objetivos de este notebook:\n",
    "1. Entender los diferentes tipos de SCD (1, 2 y 3)\n",
    "2. Implementar SCD Type 1 (Sobrescritura)\n",
    "3. Implementar SCD Type 2 (Historial Completo)\n",
    "4. Implementar SCD H√≠brido (Type 1 + Type 2)\n",
    "5. Procesar datos desde Bronze usando CDC\n",
    "\n",
    "### Conceptos clave:\n",
    "\n",
    "| Tipo SCD | Descripci√≥n | Caso de Uso |\n",
    "|----------|-------------|-------------|\n",
    "| **Type 0** | Sin cambios (valores constantes) | IDs, c√≥digos fijos |\n",
    "| **Type 1** | Sobrescribir valor anterior | Correcci√≥n de errores, datos no hist√≥ricos |\n",
    "| **Type 2** | Mantener historial completo | An√°lisis hist√≥rico, auditor√≠a, compliance |\n",
    "| **Type 3** | Mantener valor anterior y actual | Comparaci√≥n simple antes/despu√©s |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Configuraci√≥n Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable\n",
    "import uuid\n",
    "\n",
    "# Configuraci√≥n\n",
    "DATABASE_NAME = \"financial_lakehouse\"\n",
    "spark.sql(f\"USE {DATABASE_NAME}\")\n",
    "\n",
    "# Tablas Bronze (fuente)\n",
    "BRONZE_CLIENTES = \"bronze_clientes\"\n",
    "BRONZE_CUENTAS = \"bronze_cuentas\"\n",
    "\n",
    "# Tablas Silver (destino)\n",
    "SILVER_DIM_CLIENTES = \"silver_dim_clientes\"  # SCD Type 2\n",
    "SILVER_DIM_CUENTAS = \"silver_dim_cuentas\"    # SCD Type 1 + Type 2 h√≠brido\n",
    "\n",
    "print(f\"‚úÖ Configuraci√≥n cargada para {DATABASE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Crear Tablas Silver con Estructura SCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TABLA SILVER: DIMENSI√ìN CLIENTES (SCD TYPE 2)\n",
    "# ============================================\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {SILVER_DIM_CLIENTES} (\n",
    "        -- Surrogate Key (generada autom√°ticamente)\n",
    "        cliente_key BIGINT GENERATED ALWAYS AS IDENTITY COMMENT 'Surrogate key para la dimensi√≥n',\n",
    "        \n",
    "        -- Business Key (Natural Key del sistema origen)\n",
    "        cliente_id STRING NOT NULL COMMENT 'Business key - ID original del cliente',\n",
    "        \n",
    "        -- Atributos del cliente\n",
    "        nombre STRING COMMENT 'Nombre completo',\n",
    "        email STRING COMMENT 'Email del cliente',\n",
    "        telefono STRING COMMENT 'Tel√©fono',\n",
    "        direccion STRING COMMENT 'Direcci√≥n completa',\n",
    "        ciudad STRING COMMENT 'Ciudad',\n",
    "        pais STRING COMMENT 'Pa√≠s',\n",
    "        codigo_postal STRING COMMENT 'C√≥digo postal',\n",
    "        fecha_nacimiento DATE COMMENT 'Fecha de nacimiento',\n",
    "        genero STRING COMMENT 'G√©nero',\n",
    "        segmento_cliente STRING COMMENT 'Segmento: RETAIL, PREMIUM, VIP, CORPORATE',\n",
    "        estado STRING COMMENT 'Estado: ACTIVO, INACTIVO, SUSPENDIDO',\n",
    "        \n",
    "        -- Columnas SCD Type 2\n",
    "        fecha_inicio TIMESTAMP NOT NULL COMMENT 'Fecha de inicio de vigencia del registro',\n",
    "        fecha_fin TIMESTAMP COMMENT 'Fecha de fin de vigencia (NULL = registro actual)',\n",
    "        es_actual BOOLEAN NOT NULL COMMENT 'Flag que indica si es el registro vigente',\n",
    "        version INT NOT NULL COMMENT 'N√∫mero de versi√≥n del registro',\n",
    "        \n",
    "        -- Hash para detecci√≥n de cambios\n",
    "        hash_atributos STRING COMMENT 'Hash MD5 de atributos tracked para SCD2',\n",
    "        \n",
    "        -- Metadatos de auditor√≠a\n",
    "        fecha_creacion TIMESTAMP COMMENT 'Fecha de creaci√≥n del registro en Silver',\n",
    "        fecha_actualizacion TIMESTAMP COMMENT '√öltima actualizaci√≥n del registro',\n",
    "        fuente_origen STRING COMMENT 'Sistema origen de los datos'\n",
    "    )\n",
    "    USING DELTA\n",
    "    CLUSTER BY (cliente_id, es_actual)\n",
    "    COMMENT 'Dimensi√≥n de Clientes con SCD Type 2 - Historial completo de cambios'\n",
    "    TBLPROPERTIES (\n",
    "        'delta.enableChangeDataFeed' = 'true',\n",
    "        'delta.autoOptimize.optimizeWrite' = 'true',\n",
    "        'delta.columnMapping.mode' = 'name'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úÖ Tabla {SILVER_DIM_CLIENTES} creada con estructura SCD Type 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TABLA SILVER: DIMENSI√ìN CUENTAS (SCD H√çBRIDO)\n",
    "# ============================================\n",
    "# SCD Type 1: saldo_actual, saldo_disponible (sobrescribir)\n",
    "# SCD Type 2: limite_credito, estado, tipo_cuenta (historial)\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {SILVER_DIM_CUENTAS} (\n",
    "        -- Surrogate Key\n",
    "        cuenta_key BIGINT GENERATED ALWAYS AS IDENTITY COMMENT 'Surrogate key',\n",
    "        \n",
    "        -- Business Keys\n",
    "        numero_cuenta STRING NOT NULL COMMENT 'N√∫mero de cuenta √∫nico',\n",
    "        cliente_id STRING NOT NULL COMMENT 'FK al cliente',\n",
    "        \n",
    "        -- Atributos SCD Type 2 (generan nueva versi√≥n)\n",
    "        tipo_cuenta STRING COMMENT 'Tipo: AHORRO, CORRIENTE, CREDITO, INVERSION',\n",
    "        limite_credito DECIMAL(18,2) COMMENT 'L√≠mite de cr√©dito',\n",
    "        estado STRING COMMENT 'Estado: ACTIVA, BLOQUEADA, CERRADA',\n",
    "        tasa_interes DECIMAL(5,4) COMMENT 'Tasa de inter√©s',\n",
    "        sucursal STRING COMMENT 'Sucursal asignada',\n",
    "        \n",
    "        -- Atributos SCD Type 1 (sobrescribir sin historial)\n",
    "        saldo_actual DECIMAL(18,2) COMMENT 'Saldo actual - Type 1',\n",
    "        saldo_disponible DECIMAL(18,2) COMMENT 'Saldo disponible - Type 1',\n",
    "        fecha_ultimo_movimiento TIMESTAMP COMMENT '√öltimo movimiento - Type 1',\n",
    "        \n",
    "        -- Atributos est√°ticos (no cambian)\n",
    "        moneda STRING COMMENT 'C√≥digo de moneda',\n",
    "        fecha_apertura DATE COMMENT 'Fecha de apertura original',\n",
    "        ejecutivo_cuenta STRING COMMENT 'Ejecutivo asignado',\n",
    "        \n",
    "        -- Columnas SCD Type 2\n",
    "        fecha_inicio TIMESTAMP NOT NULL,\n",
    "        fecha_fin TIMESTAMP,\n",
    "        es_actual BOOLEAN NOT NULL,\n",
    "        version INT NOT NULL,\n",
    "        \n",
    "        -- Hash para SCD2 (solo columnas tracked)\n",
    "        hash_scd2 STRING COMMENT 'Hash de columnas SCD Type 2',\n",
    "        \n",
    "        -- Metadatos\n",
    "        fecha_creacion TIMESTAMP,\n",
    "        fecha_actualizacion TIMESTAMP\n",
    "    )\n",
    "    USING DELTA\n",
    "    CLUSTER BY (numero_cuenta, cliente_id, es_actual)\n",
    "    COMMENT 'Dimensi√≥n de Cuentas con SCD H√≠brido (Type 1 + Type 2)'\n",
    "    TBLPROPERTIES (\n",
    "        'delta.enableChangeDataFeed' = 'true',\n",
    "        'delta.autoOptimize.optimizeWrite' = 'true'\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úÖ Tabla {SILVER_DIM_CUENTAS} creada con estructura SCD H√≠brida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Implementaci√≥n SCD Type 2 para Clientes\n",
    "\n",
    "### L√≥gica:\n",
    "1. **Registro nuevo**: INSERT con `es_actual = true`, `version = 1`\n",
    "2. **Registro existente con cambios**: \n",
    "   - UPDATE registro anterior: `es_actual = false`, `fecha_fin = now()`\n",
    "   - INSERT nuevo registro: `es_actual = true`, `version = version + 1`\n",
    "3. **Registro existente sin cambios**: No hacer nada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FUNCI√ìN: CALCULAR HASH DE ATRIBUTOS SCD2\n",
    "# ============================================\n",
    "\n",
    "def calculate_scd2_hash(df, columns_to_track):\n",
    "    \"\"\"\n",
    "    Calcula un hash MD5 de las columnas que se rastrean para SCD Type 2.\n",
    "    Esto permite detectar cambios eficientemente.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame fuente\n",
    "        columns_to_track: Lista de columnas a incluir en el hash\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame con columna 'hash_atributos' a√±adida\n",
    "    \"\"\"\n",
    "    # Concatenar columnas y calcular MD5\n",
    "    concat_cols = concat_ws(\"||\", *[coalesce(col(c).cast(\"string\"), lit(\"NULL\")) for c in columns_to_track])\n",
    "    return df.withColumn(\"hash_atributos\", md5(concat_cols))\n",
    "\n",
    "# Definir columnas a trackear para SCD2 en Clientes\n",
    "CLIENTES_SCD2_COLUMNS = [\n",
    "    \"nombre\",\n",
    "    \"direccion\",\n",
    "    \"ciudad\",\n",
    "    \"pais\",\n",
    "    \"codigo_postal\",\n",
    "    \"segmento_cliente\",\n",
    "    \"estado\"\n",
    "]\n",
    "\n",
    "print(f\"üìã Columnas tracked para SCD2 en Clientes: {CLIENTES_SCD2_COLUMNS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FUNCI√ìN: APLICAR SCD TYPE 2\n",
    "# ============================================\n",
    "\n",
    "def apply_scd_type2(\n",
    "    source_df,\n",
    "    target_table: str,\n",
    "    business_key: list,\n",
    "    scd2_columns: list,\n",
    "    static_columns: list = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Aplica l√≥gica SCD Type 2 usando MERGE de Delta Lake.\n",
    "    \n",
    "    Args:\n",
    "        source_df: DataFrame con datos nuevos/actualizados\n",
    "        target_table: Nombre de la tabla destino\n",
    "        business_key: Lista de columnas que forman la clave de negocio\n",
    "        scd2_columns: Columnas que generan nueva versi√≥n al cambiar\n",
    "        static_columns: Columnas que nunca cambian\n",
    "    \"\"\"\n",
    "    from delta.tables import DeltaTable\n",
    "    \n",
    "    # A√±adir hash de atributos SCD2\n",
    "    source_with_hash = calculate_scd2_hash(source_df, scd2_columns)\n",
    "    \n",
    "    # Verificar si la tabla destino tiene datos\n",
    "    target_count = spark.table(target_table).count()\n",
    "    \n",
    "    if target_count == 0:\n",
    "        # Primera carga: INSERT directo\n",
    "        print(f\"üì• Carga inicial en {target_table}\")\n",
    "        \n",
    "        initial_load = source_with_hash.select(\n",
    "            *[col(c) for c in source_df.columns if c not in ['fecha_ingesta', 'operacion', 'fuente']],\n",
    "            current_timestamp().alias(\"fecha_inicio\"),\n",
    "            lit(None).cast(\"timestamp\").alias(\"fecha_fin\"),\n",
    "            lit(True).alias(\"es_actual\"),\n",
    "            lit(1).alias(\"version\"),\n",
    "            col(\"hash_atributos\"),\n",
    "            current_timestamp().alias(\"fecha_creacion\"),\n",
    "            current_timestamp().alias(\"fecha_actualizacion\"),\n",
    "            col(\"fuente\").alias(\"fuente_origen\")\n",
    "        )\n",
    "        \n",
    "        initial_load.write.format(\"delta\").mode(\"append\").saveAsTable(target_table)\n",
    "        print(f\"‚úÖ Cargados {initial_load.count()} registros iniciales\")\n",
    "        return\n",
    "    \n",
    "    # Merge para actualizaciones incrementales\n",
    "    print(f\"üîÑ Procesando cambios incrementales en {target_table}\")\n",
    "    \n",
    "    # Obtener tabla destino como DeltaTable\n",
    "    target = DeltaTable.forName(spark, target_table)\n",
    "    \n",
    "    # Construir condici√≥n de merge (business key + es_actual)\n",
    "    merge_condition = \" AND \".join([\n",
    "        f\"target.{k} = source.{k}\" for k in business_key\n",
    "    ]) + \" AND target.es_actual = true\"\n",
    "    \n",
    "    # Condici√≥n para detectar cambios (hash diferente)\n",
    "    update_condition = \"target.hash_atributos <> source.hash_atributos\"\n",
    "    \n",
    "    # Preparar source con columnas adicionales\n",
    "    source_prepared = source_with_hash.alias(\"source\")\n",
    "    \n",
    "    # Ejecutar MERGE\n",
    "    target.alias(\"target\").merge(\n",
    "        source_prepared,\n",
    "        merge_condition\n",
    "    ).whenMatchedUpdate(\n",
    "        # Cuando hay match Y el hash cambi√≥: cerrar registro anterior\n",
    "        condition=update_condition,\n",
    "        set={\n",
    "            \"fecha_fin\": current_timestamp(),\n",
    "            \"es_actual\": lit(False),\n",
    "            \"fecha_actualizacion\": current_timestamp()\n",
    "        }\n",
    "    ).whenNotMatchedInsert(\n",
    "        # Registro completamente nuevo\n",
    "        values={\n",
    "            **{k: col(f\"source.{k}\") for k in business_key},\n",
    "            **{c: col(f\"source.{c}\") for c in scd2_columns},\n",
    "            \"email\": col(\"source.email\"),\n",
    "            \"telefono\": col(\"source.telefono\"),\n",
    "            \"fecha_nacimiento\": col(\"source.fecha_nacimiento\"),\n",
    "            \"genero\": col(\"source.genero\"),\n",
    "            \"fecha_inicio\": current_timestamp(),\n",
    "            \"fecha_fin\": lit(None),\n",
    "            \"es_actual\": lit(True),\n",
    "            \"version\": lit(1),\n",
    "            \"hash_atributos\": col(\"source.hash_atributos\"),\n",
    "            \"fecha_creacion\": current_timestamp(),\n",
    "            \"fecha_actualizacion\": current_timestamp(),\n",
    "            \"fuente_origen\": col(\"source.fuente\")\n",
    "        }\n",
    "    ).execute()\n",
    "    \n",
    "    print(\"‚úÖ MERGE completado\")\n",
    "    \n",
    "    # Ahora insertar nuevas versiones para los registros que cambiaron\n",
    "    # Identificar registros que fueron marcados como no actuales\n",
    "    closed_records = spark.table(target_table).filter(\n",
    "        (col(\"es_actual\") == False) & \n",
    "        (col(\"fecha_fin\").isNotNull()) &\n",
    "        (col(\"fecha_fin\") > date_sub(current_timestamp(), 1))  # Cerrados recientemente\n",
    "    ).select(\n",
    "        *business_key,\n",
    "        col(\"version\")\n",
    "    )\n",
    "    \n",
    "    # Join con source para insertar nuevas versiones\n",
    "    new_versions = source_with_hash.alias(\"src\").join(\n",
    "        closed_records.alias(\"closed\"),\n",
    "        on=business_key,\n",
    "        how=\"inner\"\n",
    "    ).select(\n",
    "        *[col(f\"src.{c}\") for c in source_df.columns if c not in ['fecha_ingesta', 'operacion', 'fuente']],\n",
    "        current_timestamp().alias(\"fecha_inicio\"),\n",
    "        lit(None).cast(\"timestamp\").alias(\"fecha_fin\"),\n",
    "        lit(True).alias(\"es_actual\"),\n",
    "        (col(\"closed.version\") + 1).alias(\"version\"),\n",
    "        col(\"src.hash_atributos\"),\n",
    "        current_timestamp().alias(\"fecha_creacion\"),\n",
    "        current_timestamp().alias(\"fecha_actualizacion\"),\n",
    "        col(\"src.fuente\").alias(\"fuente_origen\")\n",
    "    )\n",
    "    \n",
    "    if new_versions.count() > 0:\n",
    "        new_versions.write.format(\"delta\").mode(\"append\").saveAsTable(target_table)\n",
    "        print(f\"‚úÖ Insertadas {new_versions.count()} nuevas versiones\")\n",
    "\n",
    "print(\"‚úÖ Funci√≥n apply_scd_type2 definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CARGAR DATOS DESDE BRONZE A SILVER (SCD2)\n",
    "# ============================================\n",
    "\n",
    "# Leer datos de Bronze (usando Change Data Feed para procesar solo cambios)\n",
    "bronze_clientes = spark.table(BRONZE_CLIENTES)\n",
    "\n",
    "print(f\"üìä Registros en Bronze: {bronze_clientes.count()}\")\n",
    "\n",
    "# Aplicar SCD Type 2\n",
    "apply_scd_type2(\n",
    "    source_df=bronze_clientes,\n",
    "    target_table=SILVER_DIM_CLIENTES,\n",
    "    business_key=[\"cliente_id\"],\n",
    "    scd2_columns=CLIENTES_SCD2_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar resultado\n",
    "print(f\"\\nüìã Muestra de {SILVER_DIM_CLIENTES}:\")\n",
    "spark.table(SILVER_DIM_CLIENTES).select(\n",
    "    \"cliente_key\",\n",
    "    \"cliente_id\",\n",
    "    \"nombre\",\n",
    "    \"segmento_cliente\",\n",
    "    \"ciudad\",\n",
    "    \"es_actual\",\n",
    "    \"version\",\n",
    "    \"fecha_inicio\",\n",
    "    \"fecha_fin\"\n",
    ").orderBy(\"cliente_id\", \"version\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Simular Cambios y Ver Historial SCD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SIMULAR CAMBIOS EN BRONZE PARA VER SCD2\n",
    "# ============================================\n",
    "\n",
    "# Obtener un cliente existente\n",
    "cliente_ejemplo = spark.table(SILVER_DIM_CLIENTES).filter(\n",
    "    col(\"es_actual\") == True\n",
    ").select(\"cliente_id\").first()[\"cliente_id\"]\n",
    "\n",
    "print(f\"üìå Cliente ejemplo: {cliente_ejemplo}\")\n",
    "\n",
    "# Simular cambio de segmento y direcci√≥n en Bronze\n",
    "spark.sql(f\"\"\"\n",
    "    UPDATE {BRONZE_CLIENTES}\n",
    "    SET \n",
    "        segmento_cliente = 'VIP',\n",
    "        direccion = 'Av. Los Ejecutivos 1000, Piso 15',\n",
    "        ciudad = 'San Isidro',\n",
    "        operacion = 'UPDATE',\n",
    "        fecha_ingesta = current_timestamp()\n",
    "    WHERE cliente_id = '{cliente_ejemplo}'\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úÖ Cliente {cliente_ejemplo} actualizado en Bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volver a procesar para aplicar SCD2\n",
    "bronze_clientes_updated = spark.table(BRONZE_CLIENTES)\n",
    "\n",
    "apply_scd_type2(\n",
    "    source_df=bronze_clientes_updated,\n",
    "    target_table=SILVER_DIM_CLIENTES,\n",
    "    business_key=[\"cliente_id\"],\n",
    "    scd2_columns=CLIENTES_SCD2_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver historial del cliente\n",
    "print(f\"\\nüìú Historial SCD2 para {cliente_ejemplo}:\")\n",
    "spark.table(SILVER_DIM_CLIENTES).filter(\n",
    "    col(\"cliente_id\") == cliente_ejemplo\n",
    ").select(\n",
    "    \"cliente_key\",\n",
    "    \"cliente_id\",\n",
    "    \"nombre\",\n",
    "    \"segmento_cliente\",\n",
    "    \"direccion\",\n",
    "    \"ciudad\",\n",
    "    \"es_actual\",\n",
    "    \"version\",\n",
    "    \"fecha_inicio\",\n",
    "    \"fecha_fin\"\n",
    ").orderBy(\"version\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Implementaci√≥n SCD H√≠brido (Type 1 + Type 2) para Cuentas\n",
    "\n",
    "En cuentas bancarias, algunos atributos cambian frecuentemente (saldo) y no necesitan historial, mientras que otros cambios son significativos (estado, l√≠mite de cr√©dito)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# FUNCI√ìN: APLICAR SCD H√çBRIDO (TYPE 1 + TYPE 2)\n",
    "# ============================================\n",
    "\n",
    "def apply_scd_hybrid(\n",
    "    source_df,\n",
    "    target_table: str,\n",
    "    business_key: list,\n",
    "    scd1_columns: list,  # Columnas que se sobrescriben\n",
    "    scd2_columns: list,  # Columnas que generan nueva versi√≥n\n",
    "    static_columns: list  # Columnas que nunca cambian\n",
    "):\n",
    "    \"\"\"\n",
    "    Aplica l√≥gica SCD h√≠brida:\n",
    "    - SCD Type 1: Sobrescribir valores (saldos, fechas de movimiento)\n",
    "    - SCD Type 2: Nueva versi√≥n para cambios importantes (estado, l√≠mites)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Hash solo de columnas SCD2\n",
    "    source_with_hash = source_df.withColumn(\n",
    "        \"hash_scd2\",\n",
    "        md5(concat_ws(\"||\", *[coalesce(col(c).cast(\"string\"), lit(\"NULL\")) for c in scd2_columns]))\n",
    "    )\n",
    "    \n",
    "    target_count = spark.table(target_table).count()\n",
    "    \n",
    "    if target_count == 0:\n",
    "        # Carga inicial\n",
    "        print(f\"üì• Carga inicial en {target_table}\")\n",
    "        \n",
    "        initial_df = source_with_hash.select(\n",
    "            # Business keys\n",
    "            *[col(c) for c in business_key],\n",
    "            # SCD2 columns\n",
    "            *[col(c) for c in scd2_columns],\n",
    "            # SCD1 columns\n",
    "            *[col(c) for c in scd1_columns],\n",
    "            # Static columns\n",
    "            *[col(c) for c in static_columns],\n",
    "            # SCD metadata\n",
    "            current_timestamp().alias(\"fecha_inicio\"),\n",
    "            lit(None).cast(\"timestamp\").alias(\"fecha_fin\"),\n",
    "            lit(True).alias(\"es_actual\"),\n",
    "            lit(1).alias(\"version\"),\n",
    "            col(\"hash_scd2\"),\n",
    "            current_timestamp().alias(\"fecha_creacion\"),\n",
    "            current_timestamp().alias(\"fecha_actualizacion\")\n",
    "        )\n",
    "        \n",
    "        initial_df.write.format(\"delta\").mode(\"append\").saveAsTable(target_table)\n",
    "        print(f\"‚úÖ Cargados {initial_df.count()} registros\")\n",
    "        return\n",
    "    \n",
    "    # Merge para actualizaciones\n",
    "    print(f\"üîÑ Procesando cambios h√≠bridos en {target_table}\")\n",
    "    \n",
    "    target = DeltaTable.forName(spark, target_table)\n",
    "    \n",
    "    merge_condition = \" AND \".join([\n",
    "        f\"target.{k} = source.{k}\" for k in business_key\n",
    "    ]) + \" AND target.es_actual = true\"\n",
    "    \n",
    "    # Condici√≥n SCD2: hash de columnas SCD2 diferente\n",
    "    scd2_change_condition = \"target.hash_scd2 <> source.hash_scd2\"\n",
    "    \n",
    "    # Condici√≥n SCD1: cualquier columna SCD1 diferente\n",
    "    scd1_change_conditions = \" OR \".join([\n",
    "        f\"target.{c} <> source.{c}\" for c in scd1_columns\n",
    "    ])\n",
    "    \n",
    "    source_prepared = source_with_hash.alias(\"source\")\n",
    "    \n",
    "    # Ejecutar MERGE con ambas l√≥gicas\n",
    "    target.alias(\"target\").merge(\n",
    "        source_prepared,\n",
    "        merge_condition\n",
    "    ).whenMatchedUpdate(\n",
    "        # SCD2: Cerrar registro cuando columnas importantes cambian\n",
    "        condition=scd2_change_condition,\n",
    "        set={\n",
    "            \"fecha_fin\": current_timestamp(),\n",
    "            \"es_actual\": lit(False),\n",
    "            \"fecha_actualizacion\": current_timestamp()\n",
    "        }\n",
    "    ).whenMatchedUpdate(\n",
    "        # SCD1: Sobrescribir columnas que cambian frecuentemente\n",
    "        condition=f\"NOT ({scd2_change_condition}) AND ({scd1_change_conditions})\",\n",
    "        set={\n",
    "            **{c: col(f\"source.{c}\") for c in scd1_columns},\n",
    "            \"fecha_actualizacion\": current_timestamp()\n",
    "        }\n",
    "    ).whenNotMatchedInsert(\n",
    "        values={\n",
    "            **{k: col(f\"source.{k}\") for k in business_key},\n",
    "            **{c: col(f\"source.{c}\") for c in scd2_columns},\n",
    "            **{c: col(f\"source.{c}\") for c in scd1_columns},\n",
    "            **{c: col(f\"source.{c}\") for c in static_columns},\n",
    "            \"fecha_inicio\": current_timestamp(),\n",
    "            \"fecha_fin\": lit(None),\n",
    "            \"es_actual\": lit(True),\n",
    "            \"version\": lit(1),\n",
    "            \"hash_scd2\": col(\"source.hash_scd2\"),\n",
    "            \"fecha_creacion\": current_timestamp(),\n",
    "            \"fecha_actualizacion\": current_timestamp()\n",
    "        }\n",
    "    ).execute()\n",
    "    \n",
    "    print(\"‚úÖ MERGE h√≠brido completado\")\n",
    "\n",
    "# Definir columnas para cada tipo\n",
    "CUENTAS_SCD2_COLUMNS = [\"tipo_cuenta\", \"limite_credito\", \"estado\", \"tasa_interes\", \"sucursal\"]\n",
    "CUENTAS_SCD1_COLUMNS = [\"saldo_actual\", \"saldo_disponible\", \"fecha_ultimo_movimiento\"]\n",
    "CUENTAS_STATIC_COLUMNS = [\"moneda\", \"fecha_apertura\", \"ejecutivo_cuenta\"]\n",
    "\n",
    "print(\"‚úÖ Funci√≥n apply_scd_hybrid definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CARGAR CUENTAS CON SCD H√çBRIDO\n",
    "# ============================================\n",
    "\n",
    "bronze_cuentas = spark.table(BRONZE_CUENTAS)\n",
    "\n",
    "print(f\"üìä Registros en Bronze Cuentas: {bronze_cuentas.count()}\")\n",
    "\n",
    "# Aplicar SCD h√≠brido\n",
    "apply_scd_hybrid(\n",
    "    source_df=bronze_cuentas,\n",
    "    target_table=SILVER_DIM_CUENTAS,\n",
    "    business_key=[\"numero_cuenta\", \"cliente_id\"],\n",
    "    scd1_columns=CUENTAS_SCD1_COLUMNS,\n",
    "    scd2_columns=CUENTAS_SCD2_COLUMNS,\n",
    "    static_columns=CUENTAS_STATIC_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar resultado\n",
    "print(f\"\\nüìã Muestra de {SILVER_DIM_CUENTAS}:\")\n",
    "spark.table(SILVER_DIM_CUENTAS).select(\n",
    "    \"cuenta_key\",\n",
    "    \"numero_cuenta\",\n",
    "    \"tipo_cuenta\",\n",
    "    \"saldo_actual\",\n",
    "    \"limite_credito\",\n",
    "    \"estado\",\n",
    "    \"es_actual\",\n",
    "    \"version\"\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Queries √ötiles para SCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# QUERY 1: Obtener Estado Actual de un Cliente\n",
    "# ============================================\n",
    "\n",
    "def get_current_record(table_name, business_key_col, key_value):\n",
    "    \"\"\"Obtiene el registro actual (vigente) de una dimensi√≥n SCD2\"\"\"\n",
    "    return spark.table(table_name).filter(\n",
    "        (col(business_key_col) == key_value) & \n",
    "        (col(\"es_actual\") == True)\n",
    "    )\n",
    "\n",
    "print(\"üìå Estado actual de un cliente:\")\n",
    "get_current_record(SILVER_DIM_CLIENTES, \"cliente_id\", cliente_ejemplo).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# QUERY 2: Obtener Estado a una Fecha Espec√≠fica (Time Travel)\n",
    "# ============================================\n",
    "\n",
    "def get_record_as_of(table_name, business_key_col, key_value, as_of_date):\n",
    "    \"\"\"Obtiene el registro que era vigente en una fecha espec√≠fica\"\"\"\n",
    "    return spark.table(table_name).filter(\n",
    "        (col(business_key_col) == key_value) &\n",
    "        (col(\"fecha_inicio\") <= as_of_date) &\n",
    "        ((col(\"fecha_fin\").isNull()) | (col(\"fecha_fin\") > as_of_date))\n",
    "    )\n",
    "\n",
    "# Ejemplo: Estado hace 1 hora\n",
    "from datetime import datetime, timedelta\n",
    "fecha_consulta = datetime.now() - timedelta(hours=1)\n",
    "\n",
    "print(f\"üìå Estado del cliente a las {fecha_consulta}:\")\n",
    "get_record_as_of(\n",
    "    SILVER_DIM_CLIENTES, \n",
    "    \"cliente_id\", \n",
    "    cliente_ejemplo, \n",
    "    fecha_consulta\n",
    ").select(\"cliente_id\", \"nombre\", \"segmento_cliente\", \"ciudad\", \"version\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# QUERY 3: Historial Completo de Cambios\n",
    "# ============================================\n",
    "\n",
    "def get_full_history(table_name, business_key_col, key_value):\n",
    "    \"\"\"Obtiene el historial completo de un registro\"\"\"\n",
    "    return spark.table(table_name).filter(\n",
    "        col(business_key_col) == key_value\n",
    "    ).orderBy(\"version\")\n",
    "\n",
    "print(f\"üìú Historial completo de {cliente_ejemplo}:\")\n",
    "get_full_history(SILVER_DIM_CLIENTES, \"cliente_id\", cliente_ejemplo).select(\n",
    "    \"version\",\n",
    "    \"segmento_cliente\",\n",
    "    \"ciudad\",\n",
    "    \"direccion\",\n",
    "    \"fecha_inicio\",\n",
    "    \"fecha_fin\",\n",
    "    \"es_actual\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# QUERY 4: Estad√≠sticas de SCD\n",
    "# ============================================\n",
    "\n",
    "print(\"üìä Estad√≠sticas de SCD en Clientes:\")\n",
    "\n",
    "stats = spark.table(SILVER_DIM_CLIENTES).agg(\n",
    "    count(\"*\").alias(\"total_registros\"),\n",
    "    sum(when(col(\"es_actual\") == True, 1).otherwise(0)).alias(\"registros_actuales\"),\n",
    "    sum(when(col(\"es_actual\") == False, 1).otherwise(0)).alias(\"registros_historicos\"),\n",
    "    max(\"version\").alias(\"max_versiones\"),\n",
    "    avg(\"version\").alias(\"promedio_versiones\")\n",
    ")\n",
    "\n",
    "stats.show()\n",
    "\n",
    "# Distribuci√≥n de versiones\n",
    "print(\"\\nüìà Distribuci√≥n de versiones:\")\n",
    "spark.table(SILVER_DIM_CLIENTES).groupBy(\"version\").count() \\\n",
    "    .orderBy(\"version\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Resumen y Mejores Pr√°cticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# VERIFICACI√ìN FINAL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä RESUMEN DE TABLAS SILVER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for table in [SILVER_DIM_CLIENTES, SILVER_DIM_CUENTAS]:\n",
    "    df = spark.table(table)\n",
    "    total = df.count()\n",
    "    actuales = df.filter(col(\"es_actual\") == True).count()\n",
    "    historicos = total - actuales\n",
    "    \n",
    "    print(f\"\\nüìÅ {table}:\")\n",
    "    print(f\"   ‚îî‚îÄ Total registros: {total:,}\")\n",
    "    print(f\"   ‚îî‚îÄ Registros actuales: {actuales:,}\")\n",
    "    print(f\"   ‚îî‚îÄ Registros hist√≥ricos: {historicos:,}\")\n",
    "    print(f\"   ‚îî‚îÄ Ratio hist√≥rico: {historicos/total*100:.1f}%\" if total > 0 else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Resumen del Notebook\n",
    "\n",
    "### Lo que aprendimos:\n",
    "\n",
    "1. ‚úÖ **Tipos de SCD**: Type 0, 1, 2, 3 y cu√°ndo usar cada uno\n",
    "2. ‚úÖ **SCD Type 2**: Implementaci√≥n con historial completo\n",
    "3. ‚úÖ **SCD H√≠brido**: Combinar Type 1 y Type 2 en la misma tabla\n",
    "4. ‚úÖ **Hash para detecci√≥n de cambios**: Eficiencia en comparaciones\n",
    "5. ‚úÖ **Queries temporales**: Consultar estados hist√≥ricos\n",
    "\n",
    "### Columnas SCD Type 2:\n",
    "\n",
    "| Columna | Tipo | Descripci√≥n |\n",
    "|---------|------|-------------|\n",
    "| `surrogate_key` | BIGINT | Clave sustituta √∫nica por versi√≥n |\n",
    "| `business_key` | STRING | Clave natural del sistema origen |\n",
    "| `fecha_inicio` | TIMESTAMP | Inicio de vigencia |\n",
    "| `fecha_fin` | TIMESTAMP | Fin de vigencia (NULL = actual) |\n",
    "| `es_actual` | BOOLEAN | Flag de registro vigente |\n",
    "| `version` | INT | N√∫mero de versi√≥n |\n",
    "| `hash_atributos` | STRING | Hash para detecci√≥n de cambios |\n",
    "\n",
    "### Mejores Pr√°cticas:\n",
    "\n",
    "- **Usar hash** para detectar cambios eficientemente\n",
    "- **Separar columnas SCD1 y SCD2** en tablas h√≠bridas\n",
    "- **√çndices en business_key + es_actual** para queries r√°pidos\n",
    "- **Liquid Clustering** en business_key para optimizaci√≥n\n",
    "\n",
    "### Pr√≥ximo paso:\n",
    "Continuar con el **Notebook 04: Gold Layer - Analytics** para crear m√©tricas y KPIs.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

# ğŸ¦ Proyecto End-to-End: CDC, SCD y Liquid Clustering con Datos Financieros

## Azure Databricks - GuÃ­a Paso a Paso

---

## ğŸ“‹ Tabla de Contenidos

1. [DescripciÃ³n del Proyecto](#descripciÃ³n-del-proyecto)
2. [Arquitectura de la SoluciÃ³n](#arquitectura-de-la-soluciÃ³n)
3. [Requisitos Previos](#requisitos-previos)
4. [Viabilidad de Liquid Clustering en Azure Databricks Standard](#viabilidad-de-liquid-clustering)
5. [Modelo de Datos Financieros](#modelo-de-datos-financieros)
6. [ImplementaciÃ³n Paso a Paso](#implementaciÃ³n-paso-a-paso)
7. [Notebooks del Proyecto](#notebooks-del-proyecto)
8. [OptimizaciÃ³n y Mejores PrÃ¡cticas](#optimizaciÃ³n-y-mejores-prÃ¡cticas)
9. [Troubleshooting](#troubleshooting)

---

## ğŸ“– DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline de datos financieros end-to-end utilizando las caracterÃ­sticas mÃ¡s avanzadas de Delta Lake en Azure Databricks:

| CaracterÃ­stica | DescripciÃ³n |
|----------------|-------------|
| **Change Data Capture (CDC)** | Captura de cambios incrementales en las tablas Delta |
| **Slow Changing Dimensions (SCD)** | Manejo de dimensiones histÃ³ricas Type 1 y Type 2 |
| **Liquid Clustering** | OptimizaciÃ³n automÃ¡tica del layout de datos |
| **Medallion Architecture** | Capas Bronze â†’ Silver â†’ Gold |

### Caso de Uso: Sistema Bancario

Simularemos un sistema bancario con:
- **Clientes**: InformaciÃ³n personal y demogrÃ¡fica (SCD Type 2)
- **Cuentas Bancarias**: Estado de cuentas y lÃ­mites (SCD Type 1 y 2)
- **Transacciones**: Movimientos financieros (Fact Table con CDC)

---

## ğŸ—ï¸ Arquitectura de la SoluciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AZURE DATABRICKS WORKSPACE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚   SOURCE     â”‚    â”‚    BRONZE    â”‚    â”‚    SILVER    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   SYSTEMS    â”‚â”€â”€â”€â–¶â”‚    LAYER     â”‚â”€â”€â”€â–¶â”‚    LAYER     â”‚â”€â”€â”€â–¶â”‚   GOLD   â”‚  â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚              â”‚    â”‚  LAYER   â”‚  â”‚
â”‚  â”‚ â€¢ CSV/JSON   â”‚    â”‚ â€¢ Raw Data   â”‚    â”‚ â€¢ SCD Type 1 â”‚    â”‚          â”‚  â”‚
â”‚  â”‚ â€¢ APIs       â”‚    â”‚ â€¢ CDC        â”‚    â”‚ â€¢ SCD Type 2 â”‚    â”‚ â€¢ KPIs   â”‚  â”‚
â”‚  â”‚ â€¢ Databases  â”‚    â”‚   Enabled    â”‚    â”‚ â€¢ Cleaned    â”‚    â”‚ â€¢ Aggs   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                   â”‚                â”‚        â”‚
â”‚                              â–¼                   â–¼                â–¼        â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚                    â”‚           LIQUID CLUSTERING                     â”‚     â”‚
â”‚                    â”‚  â€¢ OptimizaciÃ³n automÃ¡tica de archivos          â”‚     â”‚
â”‚                    â”‚  â€¢ Data skipping mejorado                       â”‚     â”‚
â”‚                    â”‚  â€¢ Sin necesidad de particionamiento manual     â”‚     â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos

1. **Bronze Layer**: Ingesta raw con Change Data Feed habilitado
2. **Silver Layer**: Transformaciones con SCD Type 1 y Type 2
3. **Gold Layer**: Agregaciones y mÃ©tricas financieras
4. **Liquid Clustering**: Aplicado en todas las capas para optimizaciÃ³n

---

## âœ… Requisitos Previos

### Azure Databricks Workspace

| Requisito | MÃ­nimo | Recomendado |
|-----------|--------|-------------|
| **Tier** | Standard | Premium (para Unity Catalog completo) |
| **Runtime** | 13.3 LTS | 15.2+ LTS |
| **Cluster Mode** | Single Node | Standard con autoscaling |

### ConfiguraciÃ³n del Cluster

```json
{
  "spark_version": "15.4.x-scala2.12",
  "node_type_id": "Standard_DS3_v2",
  "num_workers": 2,
  "spark_conf": {
    "spark.databricks.delta.optimizeWrite.enabled": "true",
    "spark.databricks.delta.autoCompact.enabled": "true",
    "spark.databricks.delta.properties.defaults.enableChangeDataFeed": "true"
  }
}
```

---

## ğŸ” Viabilidad de Liquid Clustering

### Â¿Funciona en Azure Databricks Standard?

| CaracterÃ­stica | Standard Tier | Premium Tier |
|----------------|---------------|--------------|
| **Liquid Clustering Manual** (`CLUSTER BY`) | âœ… SÃ­ | âœ… SÃ­ |
| **OPTIMIZE con Clustering** | âœ… SÃ­ | âœ… SÃ­ |
| **Automatic Liquid Clustering** (`CLUSTER BY AUTO`) | âŒ No* | âœ… SÃ­ |
| **Predictive Optimization** | âŒ No | âœ… SÃ­ |

> *Automatic Liquid Clustering requiere Unity Catalog con Predictive Optimization habilitado.

### Requisitos de Runtime para Liquid Clustering

```
DBR 13.3 LTS  â†’ Public Preview (limitaciones)
DBR 14.2+    â†’ DataFrame APIs disponibles
DBR 15.2+    â†’ GA (Generally Available) - RECOMENDADO
DBR 15.4 LTS â†’ Automatic Liquid Clustering disponible
```

### Beneficios de Liquid Clustering vs Partitioning/Z-Order

| Aspecto | Partitioning + Z-Order | Liquid Clustering |
|---------|------------------------|-------------------|
| Cambio de keys | Requiere reescritura | Sin reescritura |
| Mantenimiento | Alto | Bajo |
| Concurrencia | Limitada | Row-level |
| Data Skipping | Bueno | Excelente |
| Cardinality alta | Problemas | Sin problemas |

---

## ğŸ“Š Modelo de Datos Financieros

### Diagrama Entidad-RelaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     DIM_CLIENTES    â”‚         â”‚    DIM_CUENTAS      â”‚
â”‚  (SCD Type 2)       â”‚         â”‚ (SCD Type 1 & 2)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PK: cliente_key     â”‚         â”‚ PK: cuenta_key      â”‚
â”‚ BK: cliente_id      â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ FK: cliente_id      â”‚
â”‚ nombre              â”‚         â”‚ BK: numero_cuenta   â”‚
â”‚ email               â”‚         â”‚ tipo_cuenta         â”‚
â”‚ segmento_cliente    â”‚         â”‚ saldo_actual        â”‚
â”‚ direccion           â”‚         â”‚ limite_credito      â”‚
â”‚ fecha_inicio        â”‚         â”‚ estado              â”‚
â”‚ fecha_fin           â”‚         â”‚ fecha_inicio        â”‚
â”‚ es_actual           â”‚         â”‚ fecha_fin           â”‚
â”‚ version             â”‚         â”‚ es_actual           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â”‚
                                         â–¼
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚  FACT_TRANSACCIONES â”‚
                               â”‚     (CDC)           â”‚
                               â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                               â”‚ PK: transaccion_id  â”‚
                               â”‚ FK: cuenta_key      â”‚
                               â”‚ FK: cliente_key     â”‚
                               â”‚ tipo_transaccion    â”‚
                               â”‚ monto               â”‚
                               â”‚ fecha_transaccion   â”‚
                               â”‚ canal               â”‚
                               â”‚ estado              â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tipos de SCD Implementados

#### SCD Type 1 (Sobrescritura)
- **Uso**: CorrecciÃ³n de errores, datos que no requieren historial
- **Ejemplo**: CorrecciÃ³n de email, actualizaciÃ³n de telÃ©fono

#### SCD Type 2 (Historial Completo)
- **Uso**: Cambios que requieren trazabilidad histÃ³rica
- **Ejemplo**: Cambio de direcciÃ³n, cambio de segmento de cliente
- **Columnas adicionales**: `fecha_inicio`, `fecha_fin`, `es_actual`, `version`

---

## ğŸš€ ImplementaciÃ³n Paso a Paso

### Paso 1: ConfiguraciÃ³n del Ambiente

```python
# Crear base de datos
spark.sql("CREATE DATABASE IF NOT EXISTS financial_lakehouse")
spark.sql("USE financial_lakehouse")

# Habilitar CDC a nivel de sesiÃ³n (opcional)
spark.conf.set("spark.databricks.delta.properties.defaults.enableChangeDataFeed", "true")
```

### Paso 2: Crear Tablas Bronze con CDC

```python
# Ejemplo: Tabla Bronze de Clientes con CDC y Liquid Clustering
spark.sql("""
    CREATE TABLE IF NOT EXISTS bronze_clientes (
        cliente_id STRING,
        nombre STRING,
        email STRING,
        telefono STRING,
        direccion STRING,
        ciudad STRING,
        pais STRING,
        fecha_nacimiento DATE,
        segmento_cliente STRING,
        fecha_registro TIMESTAMP,
        fuente STRING,
        fecha_ingesta TIMESTAMP
    )
    USING DELTA
    CLUSTER BY (cliente_id, fecha_ingesta)
    TBLPROPERTIES (
        'delta.enableChangeDataFeed' = 'true',
        'delta.autoOptimize.optimizeWrite' = 'true'
    )
""")
```

### Paso 3: Implementar SCD Type 2 en Silver

```python
def apply_scd_type2(source_df, target_table, key_columns, tracked_columns):
    """
    Implementa SCD Type 2 usando MERGE
    """
    from delta.tables import DeltaTable
    from pyspark.sql.functions import current_timestamp, lit, col
    
    target = DeltaTable.forName(spark, target_table)
    
    # Merge condition
    merge_condition = " AND ".join([
        f"target.{k} = source.{k}" for k in key_columns
    ]) + " AND target.es_actual = true"
    
    # Update condition (detectar cambios)
    update_condition = " OR ".join([
        f"target.{c} <> source.{c}" for c in tracked_columns
    ])
    
    target.alias("target").merge(
        source_df.alias("source"),
        merge_condition
    ).whenMatchedUpdate(
        condition=update_condition,
        set={
            "fecha_fin": current_timestamp(),
            "es_actual": lit(False)
        }
    ).whenNotMatchedInsert(
        values={
            **{c: col(f"source.{c}") for c in source_df.columns},
            "fecha_inicio": current_timestamp(),
            "fecha_fin": lit(None),
            "es_actual": lit(True),
            "version": lit(1)
        }
    ).execute()
```

### Paso 4: Leer Change Data Feed

```python
# Lectura batch del CDF
changes_df = spark.read.format("delta") \
    .option("readChangeFeed", "true") \
    .option("startingVersion", 0) \
    .table("bronze_clientes")

# Lectura streaming del CDF
stream_df = spark.readStream.format("delta") \
    .option("readChangeFeed", "true") \
    .table("bronze_clientes")
```

### Paso 5: Aplicar Liquid Clustering

```python
# Optimizar tabla con Liquid Clustering
spark.sql("OPTIMIZE silver_clientes")

# Ver estadÃ­sticas de clustering
spark.sql("DESCRIBE DETAIL silver_clientes")
```

---

## ğŸ““ Notebooks del Proyecto

| Notebook | DescripciÃ³n |
|----------|-------------|
| `01_Setup_Ambiente.ipynb` | ConfiguraciÃ³n inicial, creaciÃ³n de base de datos y tablas |
| `02_Bronze_CDC.ipynb` | Ingesta de datos con Change Data Feed |
| `03_Silver_SCD.ipynb` | ImplementaciÃ³n de SCD Type 1 y Type 2 |
| `04_Gold_Analytics.ipynb` | MÃ©tricas y KPIs financieros |
| `05_Liquid_Clustering.ipynb` | OptimizaciÃ³n con Liquid Clustering |

---

## ğŸ¯ OptimizaciÃ³n y Mejores PrÃ¡cticas

### Liquid Clustering

1. **SelecciÃ³n de columnas de clustering**: MÃ¡ximo 4 columnas, ordenadas por frecuencia de filtrado
2. **Ejecutar OPTIMIZE regularmente**: DespuÃ©s de escrituras significativas
3. **No combinar con partitioning**: Liquid Clustering reemplaza el particionamiento

### Change Data Feed

1. **RetenciÃ³n**: Configurar `delta.logRetentionDuration` adecuadamente
2. **Checkpoints**: Usar checkpoints en streaming para recuperaciÃ³n
3. **Versiones**: Monitorear versiones para evitar pÃ©rdida de datos

### SCD

1. **Ãndices**: Crear Ã­ndices en columnas de bÃºsqueda frecuente
2. **CompactaciÃ³n**: Usar OPTIMIZE para mantener rendimiento
3. **Cleanup**: Implementar proceso de limpieza de versiones antiguas

---

## ğŸ”§ Troubleshooting

### Error: "Change Data Feed not enabled"

```sql
-- Habilitar CDC en tabla existente
ALTER TABLE nombre_tabla SET TBLPROPERTIES ('delta.enableChangeDataFeed' = 'true')
```

### Error: "Liquid Clustering not supported"

Verificar:
1. Runtime >= 13.3 LTS (recomendado 15.2+)
2. Tabla no tiene particionamiento
3. No se estÃ¡ usando con Z-ORDER

### Error: "Version not found"

```sql
-- Verificar historial disponible
DESCRIBE HISTORY nombre_tabla

-- Ejecutar VACUUM con precauciÃ³n
VACUUM nombre_tabla RETAIN 168 HOURS
```

---

## ğŸ“š Referencias

- [Delta Lake Change Data Feed](https://docs.databricks.com/delta/delta-change-data-feed.html)
- [Liquid Clustering Documentation](https://docs.databricks.com/delta/clustering.html)
- [SCD Implementation Patterns](https://docs.databricks.com/delta-live-tables/cdc.html)

---

